<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2019-04-03 Wed 23:20 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Kubernetes</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Hao Ruan">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="http://fonts.googleapis.com/css?family=Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />
<link href="../org-html-themes/solarized/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Kubernetes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0b2fe0b">1. Resources</a>
<ul>
<li><a href="#org1ffc80b">1.1. Pod</a>
<ul>
<li><a href="#org039c56f">1.1.1. YAML Definition</a></li>
<li><a href="#org036e6b7">1.1.2. Label</a></li>
<li><a href="#org30b0376">1.1.3. Annotation</a></li>
<li><a href="#org05c31a7">1.1.4. Deleting</a></li>
<li><a href="#org8f1e0c5">1.1.5. Liveness probes</a></li>
</ul>
</li>
<li><a href="#orgeab07cc">1.2. ReplicationController</a>
<ul>
<li><a href="#org326524a">1.2.1. Three Parts Of A Replicationcontroller</a></li>
<li><a href="#orgdbd409c">1.2.2. Create</a></li>
<li><a href="#org7dcfbea">1.2.3. Change Pod Template</a></li>
<li><a href="#orgc7171a4">1.2.4. Deleting a ReplicationController Without Deleting Pods</a></li>
</ul>
</li>
<li><a href="#org2d69096">1.3. ReplicaSet</a>
<ul>
<li><a href="#org5319c75">1.3.1. More Expressive Label Selectors</a></li>
</ul>
</li>
<li><a href="#org843b2f9">1.4. DaemonSet</a></li>
<li><a href="#orgd1c48be">1.5. Job</a>
<ul>
<li><a href="#orgdb519d0">1.5.1. Definition</a></li>
<li><a href="#orgb852d00">1.5.2. Limiting the time allowed for a Job pod to complete</a></li>
</ul>
</li>
<li><a href="#orga09eaa4">1.6. CronJob</a></li>
<li><a href="#org0dda663">1.7. Service</a>
<ul>
<li><a href="#org261729f">1.7.1. Overall</a></li>
<li><a href="#orgbc5a563">1.7.2. Creation</a>
<ul>
<li><a href="#org8d29bfe">1.7.2.1. By <code>kubectl expose</code></a></li>
<li><a href="#org19aa002">1.7.2.2. By YAML</a>
<ul>
<li><a href="#orgc21ff90">1.7.2.2.1. Exposing Multiple Ports In The Same Service</a></li>
<li><a href="#org2906ee3">1.7.2.2.2. Using Named Ports</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0ca6373">1.7.3. Session Affinity</a></li>
<li><a href="#orga46372e">1.7.4. Discovering Service</a>
<ul>
<li><a href="#org75b9383">1.7.4.1. Through ENV</a></li>
<li><a href="#orge5b2d96">1.7.4.2. Through DNS</a></li>
</ul>
</li>
<li><a href="#org63e5d09">1.7.5. Endpoints</a>
<ul>
<li><a href="#org216fe64">1.7.5.1. Manually configuring service endpoints</a></li>
<li><a href="#org5a9b498">1.7.5.2. Creating an alias for an external service</a></li>
</ul>
</li>
<li><a href="#org1686100">1.7.6. Exposing Services To External Clients</a>
<ul>
<li><a href="#org35302b3">1.7.6.1. NodePort</a>
<ul>
<li><a href="#orgdd2097a">1.7.6.1.1. YAML Definition</a></li>
</ul>
</li>
<li><a href="#org23fb929">1.7.6.2. LoadBalancer</a>
<ul>
<li><a href="#orgc60c6b5">1.7.6.2.1. YAML Definition</a></li>
</ul>
</li>
<li><a href="#org7a8744f">1.7.6.3. Ingress</a>
<ul>
<li><a href="#org6ccb222">1.7.6.3.1. YAML Definition</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgee8c5ce">1.7.7. Readiness Probe</a></li>
<li><a href="#org2b76edb">1.7.8. Headless</a></li>
<li><a href="#org5339ec8">1.7.9. External Traffic Issue</a>
<ul>
<li><a href="#org9d29310">1.7.9.1. Non-Preservation Of The Client's IP Issue</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge3e3ca0">1.8. Volume</a>
<ul>
<li><a href="#org26f730b">1.8.1. Volume Types</a></li>
<li><a href="#org614a798">1.8.2. emptyDir</a>
<ul>
<li><a href="#org663c602">1.8.2.1. The medium used</a></li>
</ul>
</li>
<li><a href="#orgfb134c3">1.8.3. hostPath</a></li>
<li><a href="#orgf5e2324">1.8.4. PV/PVC</a>
<ul>
<li><a href="#orgc5cfebd">1.8.4.1. Creating PersistentVolume</a>
<ul>
<li><a href="#org5922ed4">1.8.4.1.1. Access Mode</a></li>
</ul>
</li>
<li><a href="#org4ff9bb2">1.8.4.2. Creating PersistentVolumeClaim</a></li>
<li><a href="#org035df15">1.8.4.3. Using PersistentVolumeClaim in Pod</a></li>
<li><a href="#org9994bbd">1.8.4.4. Dynamic Provisioning of PV</a>
<ul>
<li><a href="#org72c3984">1.8.4.4.1. Defining StorageClass</a></li>
<li><a href="#orgec595b2">1.8.4.4.2. Requesting the SC in a PVC</a></li>
<li><a href="#orgd63ec53">1.8.4.4.3. Creating a PVC Without SC</a></li>
<li><a href="#org6015e18">1.8.4.4.4. Forcing a PVC to Be Bound to One of The Pre-Provisioned PVs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#orged13786">1.9. ConfigMap &amp; Secret</a>
<ul>
<li><a href="#org8b5fea1">1.9.1. Basic</a>
<ul>
<li><a href="#org59339d3">1.9.1.1. Overriding the command and arguments</a></li>
<li><a href="#org875d26c">1.9.1.2. Specifing env variables</a></li>
</ul>
</li>
<li><a href="#org21d270f">1.9.2. ConfigMap</a>
<ul>
<li><a href="#org31a4d6d">1.9.2.1. Creating</a>
<ul>
<li><a href="#org46319aa">1.9.2.1.1. CLI</a></li>
<li><a href="#orgc676fba">1.9.2.1.2. YAML</a></li>
</ul>
</li>
<li><a href="#org794219f">1.9.2.2. Passing CM to Container</a>
<ul>
<li><a href="#org32501df">1.9.2.2.1. As ENV</a></li>
<li><a href="#org0b0382f">1.9.2.2.2. As Volume</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orged8bd86">1.9.3. Secret</a>
<ul>
<li><a href="#orgefff64c">1.9.3.1. Default Token Secret</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org42ab15e">2. Internals</a>
<ul>
<li><a href="#orga060833">2.1. Container Vs VM</a></li>
<li><a href="#orge454b97">2.2. K8S components</a></li>
</ul>
</li>
<li><a href="#org3c1319a">3. YAML</a>
<ul>
<li><a href="#org88b286f">3.1. Key Value Pair</a></li>
<li><a href="#org76f40c1">3.2. Array / List</a></li>
<li><a href="#orgf1e057d">3.3. Dictionary / Map</a></li>
</ul>
</li>
<li><a href="#orge11b396">4. 核心原理</a>
<ul>
<li><a href="#orgc57e234">4.1. 资源对象</a>
<ul>
<li><a href="#org56d639b">4.1.1. POD</a>
<ul>
<li><a href="#org840afb9">4.1.1.1. 基本 YAML 定义</a></li>
<li><a href="#org8475f92">4.1.1.2. 设计理念</a></li>
<li><a href="#org610d487">4.1.1.3. 生命周期</a></li>
<li><a href="#org43137be">4.1.1.4. 重启策略(restartPolicy)</a></li>
<li><a href="#orga07e02d">4.1.1.5. 使用 Volume</a></li>
<li><a href="#org89c3604">4.1.1.6. 环境变量</a></li>
<li><a href="#org4a80b4e">4.1.1.7. 镜像拉取策略(ImagePullPolicy)</a></li>
<li><a href="#org0f108b0">4.1.1.8. DNS 策略</a></li>
<li><a href="#orge5f7d37">4.1.1.9. Health Probe</a></li>
<li><a href="#org2d76219">4.1.1.10. 调度到指定 Node 上</a></li>
<li><a href="#org36c011e">4.1.1.11. 常用命令</a>
<ul>
<li><a href="#org9fcff90">4.1.1.11.1. 查看 Pod 状态</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org383dc92">4.1.2. Replica Set</a>
<ul>
<li><a href="#org44a468b">4.1.2.1. YAML 定义</a></li>
<li><a href="#orgb3c2432">4.1.2.2. 常用命令</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org11b6311">5. Utils</a>
<ul>
<li><a href="#org2bba3ed">5.1. Bash completion</a></li>
<li><a href="#orgfa9dd1e">5.2. Show all resources</a></li>
<li><a href="#org059ee1a">5.3. Discover possible API object fields</a></li>
<li><a href="#org05184e6">5.4. Quickly switch to a different namespace</a></li>
<li><a href="#orgdc335f1">5.5. Forwarding a local network port to a port in the pod</a></li>
<li><a href="#org82ae919">5.6. Obtaining the application log of a crashed container</a></li>
<li><a href="#orgd476888">5.7. Get IPs of all nodes</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="meta">
<table>


<colgroup>
<col  class="org-left">

<col  class="org-left">
</colgroup>
<tbody>
<tr>
<td class="org-left">Author</td>
<td class="org-left">Hao Ruan (haoru@cisco.com)</td>
</tr>

<tr>
<td class="org-left">Date</td>
<td class="org-left">2019-04-03 23:20:12</td>
</tr>
</tbody>
</table>
</div>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0b2fe0b">1. Resources</a>
<ul>
<li><a href="#org1ffc80b">1.1. Pod</a>
<ul>
<li><a href="#org039c56f">1.1.1. YAML Definition</a></li>
<li><a href="#org036e6b7">1.1.2. Label</a></li>
<li><a href="#org30b0376">1.1.3. Annotation</a></li>
<li><a href="#org05c31a7">1.1.4. Deleting</a></li>
<li><a href="#org8f1e0c5">1.1.5. Liveness probes</a></li>
</ul>
</li>
<li><a href="#orgeab07cc">1.2. ReplicationController</a>
<ul>
<li><a href="#org326524a">1.2.1. Three Parts Of A Replicationcontroller</a></li>
<li><a href="#orgdbd409c">1.2.2. Create</a></li>
<li><a href="#org7dcfbea">1.2.3. Change Pod Template</a></li>
<li><a href="#orgc7171a4">1.2.4. Deleting a ReplicationController Without Deleting Pods</a></li>
</ul>
</li>
<li><a href="#org2d69096">1.3. ReplicaSet</a>
<ul>
<li><a href="#org5319c75">1.3.1. More Expressive Label Selectors</a></li>
</ul>
</li>
<li><a href="#org843b2f9">1.4. DaemonSet</a></li>
<li><a href="#orgd1c48be">1.5. Job</a>
<ul>
<li><a href="#orgdb519d0">1.5.1. Definition</a></li>
<li><a href="#orgb852d00">1.5.2. Limiting the time allowed for a Job pod to complete</a></li>
</ul>
</li>
<li><a href="#orga09eaa4">1.6. CronJob</a></li>
<li><a href="#org0dda663">1.7. Service</a>
<ul>
<li><a href="#org261729f">1.7.1. Overall</a></li>
<li><a href="#orgbc5a563">1.7.2. Creation</a>
<ul>
<li><a href="#org8d29bfe">1.7.2.1. By <code>kubectl expose</code></a></li>
<li><a href="#org19aa002">1.7.2.2. By YAML</a>
<ul>
<li><a href="#orgc21ff90">1.7.2.2.1. Exposing Multiple Ports In The Same Service</a></li>
<li><a href="#org2906ee3">1.7.2.2.2. Using Named Ports</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0ca6373">1.7.3. Session Affinity</a></li>
<li><a href="#orga46372e">1.7.4. Discovering Service</a>
<ul>
<li><a href="#org75b9383">1.7.4.1. Through ENV</a></li>
<li><a href="#orge5b2d96">1.7.4.2. Through DNS</a></li>
</ul>
</li>
<li><a href="#org63e5d09">1.7.5. Endpoints</a>
<ul>
<li><a href="#org216fe64">1.7.5.1. Manually configuring service endpoints</a></li>
<li><a href="#org5a9b498">1.7.5.2. Creating an alias for an external service</a></li>
</ul>
</li>
<li><a href="#org1686100">1.7.6. Exposing Services To External Clients</a>
<ul>
<li><a href="#org35302b3">1.7.6.1. NodePort</a>
<ul>
<li><a href="#orgdd2097a">1.7.6.1.1. YAML Definition</a></li>
</ul>
</li>
<li><a href="#org23fb929">1.7.6.2. LoadBalancer</a>
<ul>
<li><a href="#orgc60c6b5">1.7.6.2.1. YAML Definition</a></li>
</ul>
</li>
<li><a href="#org7a8744f">1.7.6.3. Ingress</a>
<ul>
<li><a href="#org6ccb222">1.7.6.3.1. YAML Definition</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgee8c5ce">1.7.7. Readiness Probe</a></li>
<li><a href="#org2b76edb">1.7.8. Headless</a></li>
<li><a href="#org5339ec8">1.7.9. External Traffic Issue</a>
<ul>
<li><a href="#org9d29310">1.7.9.1. Non-Preservation Of The Client's IP Issue</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge3e3ca0">1.8. Volume</a>
<ul>
<li><a href="#org26f730b">1.8.1. Volume Types</a></li>
<li><a href="#org614a798">1.8.2. emptyDir</a>
<ul>
<li><a href="#org663c602">1.8.2.1. The medium used</a></li>
</ul>
</li>
<li><a href="#orgfb134c3">1.8.3. hostPath</a></li>
<li><a href="#orgf5e2324">1.8.4. PV/PVC</a>
<ul>
<li><a href="#orgc5cfebd">1.8.4.1. Creating PersistentVolume</a>
<ul>
<li><a href="#org5922ed4">1.8.4.1.1. Access Mode</a></li>
</ul>
</li>
<li><a href="#org4ff9bb2">1.8.4.2. Creating PersistentVolumeClaim</a></li>
<li><a href="#org035df15">1.8.4.3. Using PersistentVolumeClaim in Pod</a></li>
<li><a href="#org9994bbd">1.8.4.4. Dynamic Provisioning of PV</a>
<ul>
<li><a href="#org72c3984">1.8.4.4.1. Defining StorageClass</a></li>
<li><a href="#orgec595b2">1.8.4.4.2. Requesting the SC in a PVC</a></li>
<li><a href="#orgd63ec53">1.8.4.4.3. Creating a PVC Without SC</a></li>
<li><a href="#org6015e18">1.8.4.4.4. Forcing a PVC to Be Bound to One of The Pre-Provisioned PVs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#orged13786">1.9. ConfigMap &amp; Secret</a>
<ul>
<li><a href="#org8b5fea1">1.9.1. Basic</a>
<ul>
<li><a href="#org59339d3">1.9.1.1. Overriding the command and arguments</a></li>
<li><a href="#org875d26c">1.9.1.2. Specifing env variables</a></li>
</ul>
</li>
<li><a href="#org21d270f">1.9.2. ConfigMap</a>
<ul>
<li><a href="#org31a4d6d">1.9.2.1. Creating</a>
<ul>
<li><a href="#org46319aa">1.9.2.1.1. CLI</a></li>
<li><a href="#orgc676fba">1.9.2.1.2. YAML</a></li>
</ul>
</li>
<li><a href="#org794219f">1.9.2.2. Passing CM to Container</a>
<ul>
<li><a href="#org32501df">1.9.2.2.1. As ENV</a></li>
<li><a href="#org0b0382f">1.9.2.2.2. As Volume</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orged8bd86">1.9.3. Secret</a>
<ul>
<li><a href="#orgefff64c">1.9.3.1. Default Token Secret</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org42ab15e">2. Internals</a>
<ul>
<li><a href="#orga060833">2.1. Container Vs VM</a></li>
<li><a href="#orge454b97">2.2. K8S components</a></li>
</ul>
</li>
<li><a href="#org3c1319a">3. YAML</a>
<ul>
<li><a href="#org88b286f">3.1. Key Value Pair</a></li>
<li><a href="#org76f40c1">3.2. Array / List</a></li>
<li><a href="#orgf1e057d">3.3. Dictionary / Map</a></li>
</ul>
</li>
<li><a href="#orge11b396">4. 核心原理</a>
<ul>
<li><a href="#orgc57e234">4.1. 资源对象</a>
<ul>
<li><a href="#org56d639b">4.1.1. POD</a>
<ul>
<li><a href="#org840afb9">4.1.1.1. 基本 YAML 定义</a></li>
<li><a href="#org8475f92">4.1.1.2. 设计理念</a></li>
<li><a href="#org610d487">4.1.1.3. 生命周期</a></li>
<li><a href="#org43137be">4.1.1.4. 重启策略(restartPolicy)</a></li>
<li><a href="#orga07e02d">4.1.1.5. 使用 Volume</a></li>
<li><a href="#org89c3604">4.1.1.6. 环境变量</a></li>
<li><a href="#org4a80b4e">4.1.1.7. 镜像拉取策略(ImagePullPolicy)</a></li>
<li><a href="#org0f108b0">4.1.1.8. DNS 策略</a></li>
<li><a href="#orge5f7d37">4.1.1.9. Health Probe</a></li>
<li><a href="#org2d76219">4.1.1.10. 调度到指定 Node 上</a></li>
<li><a href="#org36c011e">4.1.1.11. 常用命令</a>
<ul>
<li><a href="#org9fcff90">4.1.1.11.1. 查看 Pod 状态</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org383dc92">4.1.2. Replica Set</a>
<ul>
<li><a href="#org44a468b">4.1.2.1. YAML 定义</a></li>
<li><a href="#orgb3c2432">4.1.2.2. 常用命令</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org11b6311">5. Utils</a>
<ul>
<li><a href="#org2bba3ed">5.1. Bash completion</a></li>
<li><a href="#orgfa9dd1e">5.2. Show all resources</a></li>
<li><a href="#org059ee1a">5.3. Discover possible API object fields</a></li>
<li><a href="#org05184e6">5.4. Quickly switch to a different namespace</a></li>
<li><a href="#orgdc335f1">5.5. Forwarding a local network port to a port in the pod</a></li>
<li><a href="#org82ae919">5.6. Obtaining the application log of a crashed container</a></li>
<li><a href="#orgd476888">5.7. Get IPs of all nodes</a></li>
</ul>
</li>
</ul>
</div>
</div>



<div id="outline-container-org0b2fe0b" class="outline-2">
<h2 id="org0b2fe0b"><span class="section-number-2">1</span> Resources</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org1ffc80b" class="outline-3">
<h3 id="org1ffc80b"><span class="section-number-3">1.1</span> Pod</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org039c56f" class="outline-4">
<h4 id="org039c56f"><span class="section-number-4">1.1.1</span> YAML Definition</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
定义文件主要包含：
</p>

<ol class="org-ol">
<li>API version</li>
<li>Resource type</li>
<li>Metadata <br>
Includes the name, namespace, labels, and other information about the pod.</li>
<li>Spec <br>
Contains the actual description of the pod’s contents, such as the pod’s con- tainers, volumes, and other data.</li>
<li>Status<br>
Contains read-only runtime data that shows the state of the resource at a given moment.<br>
<b>When creating a new pod, you never need to provide the status part.</b></li>
</ol>



<div class="figure">
<p><img src="img/k8s_pod_def.png" alt="k8s_pod_def.png">
</p>
</div>


<pre class="example">
  在 POD 定义文件中定义 ports 是可选的行为，端口始终可以被访问，主要是为了方便用户清楚的了解提供了哪些服务。
</pre>
</div>
</div>



<div id="outline-container-org036e6b7" class="outline-4">
<h4 id="org036e6b7"><span class="section-number-4">1.1.2</span> Label</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
A label is an arbitrary key-value pair you attach to a resource, <br>
which is then utilized when selecting resources using <b>label selectors</b> <br>
(resources are filtered based on whether they include the label specified in the selector).
</p>


<div class="figure">
<p><img src="img/k8s_labels.png" alt="k8s_labels.png">
</p>
</div>

<p>
A label selector can select resources based on whether the resource:
</p>

<ol class="org-ol">
<li>Contains (or doesn’t contain) a label with a certain key <br></li>
<li>Contains a label with a certain key and value <br></li>
<li>Contains a label with a certain key, but with a value not equal to the one you specify</li>
</ol>
</div>
</div>


<div id="outline-container-org30b0376" class="outline-4">
<h4 id="org30b0376"><span class="section-number-4">1.1.3</span> Annotation</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
Annotations are also key-value pairs, so in essence, they’re similar to labels,
but they aren’t meant to hold identifying information.
</p>

<p>
They can’t be used to group objects the way labels can.
While objects can be selected through label selectors, <b>there’s no such thing as an annotation selector.</b>
</p>

<p>
Annotations can hold much larger pieces of information (up to 256 KB in total) and are primarily <b>meant to be used by tools.</b>
</p>

<pre class="example">
Annotations are also commonly used when introducing new features to Kubernetes.
Usually, alpha and beta versions of new features don’t introduce any new fields to API objects.
Annotations are used instead of fields, and then once the required API changes have become clear and been agreed upon by the Kubernetes developers, new fields are introduced and the related annotations deprecated.

A great use of annotations is adding descriptions for each pod or other API object, so that everyone using the cluster can quickly look up information about each individual object.
For example, an annotation used to specify the name of the person who created the object can make collaboration between everyone working on the cluster much easier.
</pre>
</div>
</div>


<div id="outline-container-org05c31a7" class="outline-4">
<h4 id="org05c31a7"><span class="section-number-4">1.1.4</span> Deleting</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
By deleting a pod, you’re instructing Kubernetes to terminate all the containers that are part of that pod.
</p>

<p>
Kubernetes sends a <b>SIGTERM</b> signal to the process and waits a certain number of seconds (30 by default) for it to shut down gracefully.
</p>

<p>
If it doesn’t shut down in time, the process is then killed through <b>SIGKILL</b>.
To make sure your processes are always shut down gracefully, they need to handle the SIGTERM signal properly.
</p>
</div>
</div>


<div id="outline-container-org8f1e0c5" class="outline-4">
<h4 id="org8f1e0c5"><span class="section-number-4">1.1.5</span> Liveness probes</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
As soon as a pod is scheduled to a node, the Kubelet on that node will run its containers and, from then on, <b>keep them running as long as the pod exists.</b>
</p>

<p>
If the container’s main process crashes, <b>the Kubelet will restart the container.</b>
</p>

<p>
Kubernetes can check if a <b>container</b> is still alive through <code>liveness probes</code>.
</p>

<p>
You can specify a liveness probe for each container in the pod’s specification.
Kubernetes will periodically execute the probe and restart the container if the probe fails.
</p>

<pre class="example">
Kubernetes also supports readiness probes. Be sure not to confuse the two. They’re used for two different things.
</pre>



<div class="figure">
<p><img src="img/k8s_pod_liveness.png" alt="k8s_pod_liveness.png">
</p>
</div>

<pre class="example">
Liveness:       http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3

The delay=0s part shows that the probing begins immediately after the container is started.
If you don’t set the initial delay, the prober will start probing the container as soon as it starts,
which usually leads to the probe failing, because the app isn’t ready to start receiving requests.

The timeout is set to only 1 second, so the container must return a response in 1 second or the probe is counted as failed.

The container is probed every 10 seconds (period=10s) and the container is restarted after the probe fails three consecutive times (#failure=3).
</pre>
</div>
</div>
</div>


<div id="outline-container-orgeab07cc" class="outline-3">
<h3 id="orgeab07cc"><span class="section-number-3">1.2</span> ReplicationController</h3>
<div class="outline-text-3" id="text-1-2">
<p>
A ReplicationController’s job is to make sure that an exact number of pods always <b>matches its label selector.</b> <br>
If it doesn’t, the ReplicationController takes the appropriate action to reconcile the actual with the desired number.
</p>


<div class="figure">
<p><img src="img/k8s_rc_loop.png" alt="k8s_rc_loop.png">
</p>
</div>
</div>


<div id="outline-container-org326524a" class="outline-4">
<h4 id="org326524a"><span class="section-number-4">1.2.1</span> Three Parts Of A Replicationcontroller</h4>
<div class="outline-text-4" id="text-1-2-1">

<div class="figure">
<p><img src="img/k8s_rc_3parts.png" alt="k8s_rc_3parts.png">
</p>
</div>


<p>
A ReplicationController’s replica count, the label selector, and even the pod template can all be modified at any time,
<b>but only changes to the replica count affect existing pods.</b>
</p>
</div>
</div>


<div id="outline-container-orgdbd409c" class="outline-4">
<h4 id="orgdbd409c"><span class="section-number-4">1.2.2</span> Create</h4>
<div class="outline-text-4" id="text-1-2-2">

<div class="figure">
<p><img src="img/k8s_rc_def.png" alt="k8s_rc_def.png">
</p>
</div>

<p>
The pod labels in the template must obviously match the label selector of the ReplicationController;
otherwise the controller would create new pods indefinitely, because spinning up a new pod wouldn’t bring the actual replica count any closer to the desired number of replicas.
</p>

<p>
To prevent such scenarios, the API server verifies the ReplicationController definition and will not accept it if it’s misconfigured.
<b>Not specifying the selector at all is also an option.</b> In that case, it will be configured automatically from the labels in the pod template.
</p>


<pre class="example">
Don’t specify a pod selector when defining a ReplicationController.
Let Kubernetes extract it from the pod template. This will keep your YAML shorter and simpler.
</pre>

<p>
Although a pod isn’t tied to a ReplicationController, the pod does reference it in the <code>metadata.ownerReferences</code> field, <br>
which you can use to easily find which ReplicationController a pod belongs to.
</p>
</div>
</div>


<div id="outline-container-org7dcfbea" class="outline-4">
<h4 id="org7dcfbea"><span class="section-number-4">1.2.3</span> Change Pod Template</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
A ReplicationController’s pod template can be modified at any time. <br>
Changing the pod template is like replacing a cookie cutter with another one. <br>
It will only affect the cookies you cut out afterward and will have no effect on the ones you’ve already cut. <br>
To modify the old pods, you’d need to delete them and let the ReplicationController replace them with new ones based on the new template.
</p>


<div class="figure">
<p><img src="img/k8s_rc_change_pod_tmpl.png" alt="k8s_rc_change_pod_tmpl.png">
</p>
</div>
</div>
</div>


<div id="outline-container-orgc7171a4" class="outline-4">
<h4 id="orgc7171a4"><span class="section-number-4">1.2.4</span> Deleting a ReplicationController Without Deleting Pods</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
When you delete a ReplicationController through kubectl delete, the pods are also deleted.<br>
But because pods created by a ReplicationController aren’t an integral part of the ReplicationController, and are only managed by it, <br>
<b>you can delete only the ReplicationController and leave the pods running:</b>
</p>

<div class="org-src-container">
<pre class="src src-sh">kubectl delete rc &lt;rc-name&gt; --cascade=false
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org2d69096" class="outline-3">
<h3 id="org2d69096"><span class="section-number-3">1.3</span> ReplicaSet</h3>
<div class="outline-text-3" id="text-1-3">
<p>
You usually won’t create them directly, but instead have them created automatically <b>when you create the higher-level Deployment resource.</b>
</p>

<p>
A ReplicaSet behaves exactly like a ReplicationController, but it has <b>more expressive pod selectors.</b>
</p>
</div>

<div id="outline-container-org5319c75" class="outline-4">
<h4 id="org5319c75"><span class="section-number-4">1.3.1</span> More Expressive Label Selectors</h4>
<div class="outline-text-4" id="text-1-3-1">

<div class="figure">
<p><img src="img/k8s_rs_label_selector.png" alt="k8s_rs_label_selector.png">
</p>
</div>

<p>
Each expression must contain <span class="underline">a key</span>, <span class="underline">an operator</span>, and possibly (depending on the operator) <span class="underline">a list of values</span>. <br>
Four valid operators:
</p>

<dl class="org-dl">
<dt>In</dt><dd>Label’s value must match one of the specified <span class="underline">values</span>.</dd>
<dt>NotIn</dt><dd>Label’s value must not match any of the specified <span class="underline">values</span>.</dd>
<dt>Exists</dt><dd>Pod must include a label with the specified key (the value isn’t important). When using this operator, you shouldn’t specify the <span class="underline">values</span> field.</dd>
<dt>DoesNotExist</dt><dd>Pod must not include a label with the specified key. The <span class="underline">values</span> property must not be specified.</dd>
</dl>
</div>
</div>
</div>


<div id="outline-container-org843b2f9" class="outline-3">
<h3 id="org843b2f9"><span class="section-number-3">1.4</span> DaemonSet</h3>
<div class="outline-text-3" id="text-1-4">
<p>
DaemonSet is used when you want <b>a pod to run on each and every node in the cluster</b> <br>
(and each node needs to run exactly <b>one instance of the pod</b>).
</p>


<div class="figure">
<p><img src="img/k8s_ds.png" alt="k8s_ds.png">
</p>
</div>

<p>
To run a pod on all cluster nodes, you create a DaemonSet object, which is much like a ReplicationController or a ReplicaSet, <br>
except that pods created by a DaemonSet already have a target node specified and <b>skip the Kubernetes Scheduler.</b>
</p>
</div>
</div>


<div id="outline-container-orgd1c48be" class="outline-3">
<h3 id="orgd1c48be"><span class="section-number-3">1.5</span> Job</h3>
<div class="outline-text-3" id="text-1-5">
<p>
<b>In the event of a node failure</b>, the pods on that node that are managed by a Job will be rescheduled to other nodes the way ReplicaSet pods are. <br>
<b>In the event of a failure of the process itself</b> (when the process returns an error exit code), <br>
the Job can be configured to either restart the container or not.
</p>
</div>


<div id="outline-container-orgdb519d0" class="outline-4">
<h4 id="orgdb519d0"><span class="section-number-4">1.5.1</span> Definition</h4>
<div class="outline-text-4" id="text-1-5-1">

<div class="figure">
<p><img src="img/k8s_job_def.png" alt="k8s_job_def.png">
</p>
</div>


<p>
Job pods can't use the default policy, because they're not meant to run indefinitely. <br>
Need to explicitly set the restart policy to either <code>OnFailure</code> or <code>Never</code>.
</p>
</div>
</div>


<div id="outline-container-orgb852d00" class="outline-4">
<h4 id="orgb852d00"><span class="section-number-4">1.5.2</span> Limiting the time allowed for a Job pod to complete</h4>
<div class="outline-text-4" id="text-1-5-2">
<p>
A pod's time can be limited by setting the <code>activeDeadlineSeconds</code> property in the pod spec. <br>
If the pod runs longer than that, the system will try to terminate it and will mark the Job as failed.
</p>

<pre class="example">
You can configure how many times a Job can be retried before it is marked as failed by specifying the spec.backoffLimit field in the Job manifest.
If you don't explicitly specify it, it defaults to 6.
</pre>
</div>
</div>
</div>



<div id="outline-container-orga09eaa4" class="outline-3">
<h3 id="orga09eaa4"><span class="section-number-3">1.6</span> CronJob</h3>
<div class="outline-text-3" id="text-1-6">
<p>
A CronJob creates Job resources from the <code>jobTemplate</code> property configured in the CronJob spec. <br>
The Job then creates the pods.
</p>
</div>
</div>


<div id="outline-container-org0dda663" class="outline-3">
<h3 id="org0dda663"><span class="section-number-3">1.7</span> Service</h3>
<div class="outline-text-3" id="text-1-7">
</div>
<div id="outline-container-org261729f" class="outline-4">
<h4 id="org261729f"><span class="section-number-4">1.7.1</span> Overall</h4>
<div class="outline-text-4" id="text-1-7-1">
<p>
Although the primary purpose of services is exposing groups of pods to other pods <b>in the cluster</b>, <br>
<b>Both</b> internal (by DNS or ENV) and external (by IP) clients usually connect to pods through services:
</p>


<div class="figure">
<p><img src="img/k8s_svc_overall.png" alt="k8s_svc_overall.png">
</p>
</div>

<p>
<b>Label selectors</b> determine which pods belong to the Service:
</p>


<div class="figure">
<p><img src="img/k8s_svc_label.png" alt="k8s_svc_label.png">
</p>
</div>
</div>
</div>


<div id="outline-container-orgbc5a563" class="outline-4">
<h4 id="orgbc5a563"><span class="section-number-4">1.7.2</span> Creation</h4>
<div class="outline-text-4" id="text-1-7-2">
</div>
<div id="outline-container-org8d29bfe" class="outline-5">
<h5 id="org8d29bfe"><span class="section-number-5">1.7.2.1</span> By <code>kubectl expose</code></h5>
</div>


<div id="outline-container-org19aa002" class="outline-5">
<h5 id="org19aa002"><span class="section-number-5">1.7.2.2</span> By YAML</h5>
<div class="outline-text-5" id="text-1-7-2-2">

<div class="figure">
<p><img src="img/k8s_svc_def.png" alt="k8s_svc_def.png">
</p>
</div>
</div>

<div id="outline-container-orgc21ff90" class="outline-6">
<h6 id="orgc21ff90"><span class="section-number-6">1.7.2.2.1</span> Exposing Multiple Ports In The Same Service</h6>
<div class="outline-text-6" id="text-1-7-2-2-1">
<pre class="example">
When creating a service with multiple ports, you must specify a name for each port.
</pre>

<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Service
metadata:
  name: kubia
spec: ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: https
    port: 443
    targetPort: 8443
  selector:
    app: kubia
</pre>
</div>
</div>
</div>


<div id="outline-container-org2906ee3" class="outline-6">
<h6 id="org2906ee3"><span class="section-number-6">1.7.2.2.2</span> Using Named Ports</h6>
<div class="outline-text-6" id="text-1-7-2-2-2">

<div class="figure">
<p><img src="img/k8s_svc_named_ports_container.png" alt="k8s_svc_named_ports_container.png">
</p>
</div>

<p>
You can then refer to those ports by name in the service spec:
</p>


<div class="figure">
<p><img src="img/k8s_svc_named_ports_pod.png" alt="k8s_svc_named_ports_pod.png">
</p>
</div>

<pre class="example">
The biggest benefit of doing so is that it enables you to change port numbers later without having to change the service spec.
</pre>
</div>
</div>
</div>
</div>





<div id="outline-container-org0ca6373" class="outline-4">
<h4 id="org0ca6373"><span class="section-number-4">1.7.3</span> Session Affinity</h4>
<div class="outline-text-4" id="text-1-7-3">
<p>
If you want all requests made by a certain client to be redirected to the <b>same</b> pod every time, <br>
you can set the service's <span class="underline">sessionAffinity</span> property to <code>ClientIP</code> (instead of <code>None</code>, which is the default).
</p>

<p>
This makes the service proxy redirect all requests originating <b>from the same client IP to the same pod.</b>
</p>


<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Service
spec:
  sessionAffinity: ClientIP
...
</pre>
</div>
</div>
</div>





<div id="outline-container-orga46372e" class="outline-4">
<h4 id="orga46372e"><span class="section-number-4">1.7.4</span> Discovering Service</h4>
<div class="outline-text-4" id="text-1-7-4">
</div>
<div id="outline-container-org75b9383" class="outline-5">
<h5 id="org75b9383"><span class="section-number-5">1.7.4.1</span> Through ENV</h5>
<div class="outline-text-5" id="text-1-7-4-1">
<pre class="example">
Dashes in the service name are converted to underscores and all letters are uppercased
when the service name is used as the prefix in the environment variable's name.
</pre>
</div>
</div>

<div id="outline-container-orge5b2d96" class="outline-5">
<h5 id="orge5b2d96"><span class="section-number-5">1.7.4.2</span> Through DNS</h5>
<div class="outline-text-5" id="text-1-7-4-2">
<pre class="example">
kubia        .default  .svc.cluster.local
------------
service name
             ---------
             namespace
                       ------------------
                       configurable cluster domain suffix
</pre>

<p>
<b>You can omit the <code>svc.cluster.local</code> suffix and even the namespace, when pods are in the same namespace.</b> <br>
(This is because how <code>/etc/resolv.conf</code> is configured)
</p>


<pre class="example">
Whether a pod uses the internal DNS server or not is configurable through the 'dnsPolicy' property in each pod's spec.
</pre>
</div>
</div>
</div>


<div id="outline-container-org63e5d09" class="outline-4">
<h4 id="org63e5d09"><span class="section-number-4">1.7.5</span> Endpoints</h4>
<div class="outline-text-4" id="text-1-7-5">
<p>
Services don't link to pods directly, but <b>Endpoints</b>. <br>
An Endpoints resource (plural) is <b>a list of IP addresses and ports</b> exposing a service.
</p>


<div class="figure">
<p><img src="img/k8s_svc_endpoints.png" alt="k8s_svc_endpoints.png">
</p>
</div>


<pre class="example">
Although the pod selector is defined in the service spec, it's not used directly when redirecting incoming connections.
Instead, the selector is used to build a list of IPs and ports, which is then stored in the Endpoints resource.

If you create a service without a pod selector, Kubernetes won't even create the Endpoints resource
(after all, without a selector, it can't know which pods to include in the service).
It's up to you to create the Endpoints resource to specify the list of endpoints for the service.
</pre>
</div>

<div id="outline-container-org216fe64" class="outline-5">
<h5 id="org216fe64"><span class="section-number-5">1.7.5.1</span> Manually configuring service endpoints</h5>
<div class="outline-text-5" id="text-1-7-5-1">
<p>
To create a service with manually managed endpoints, you need to create both a Service and an Endpoints resource.
</p>

<p>
Define a service called external-service that will accept incoming connections on port 80 (didn't define a pod selector for the service):
</p>


<div class="figure">
<p><img src="img/k8s_svc_manual_ep_svc.png" alt="k8s_svc_manual_ep_svc.png">
</p>
</div>


<p>
The Endpoints object needs to <b>have the same name as the service</b> and contain the list of target IP addresses and ports for the service:
</p>


<div class="figure">
<p><img src="img/k8s_svc_manual_ep_ep.png" alt="k8s_svc_manual_ep_ep.png">
</p>
</div>

<p>
After both the Service and the Endpoints resource are posted to the server, <br>
the service is ready to be used like any regular service with a pod selector:
</p>


<div class="figure">
<p><img src="img/k8s_svc_manual_ep_external.png" alt="k8s_svc_manual_ep_external.png">
</p>
</div>

<p>
If you later decide to migrate the external service to pods running inside Kubernetes, <br>
you can add a selector to the service, thereby making its Endpoints managed automatically.
The same is also true in reverse by removing the selector from a Service, Kubernetes stops updating its Endpoints. <br>
This means a service IP address can remain constant while the actual implementation of the service is changed.
</p>
</div>
</div>





<div id="outline-container-org5a9b498" class="outline-5">
<h5 id="org5a9b498"><span class="section-number-5">1.7.5.2</span> Creating an alias for an external service</h5>
<div class="outline-text-5" id="text-1-7-5-2">

<div class="figure">
<p><img src="img/k8s_svc_external_name.png" alt="k8s_svc_external_name.png">
</p>
</div>

<p>
After the service is created, pods can connect to the external service through the <code>external-service.default.svc.cluster.local</code> domain name.
</p>

<pre class="example">
ExternalName services are implemented solely at the DNS level: a simple CNAME DNS record is created for the service.
Therefore, clients connecting to the service will connect to the external service directly, bypassing the service proxy completely.
For this reason, these types of services don't even get a cluster IP.
</pre>
</div>
</div>
</div>



<div id="outline-container-org1686100" class="outline-4">
<h4 id="org1686100"><span class="section-number-4">1.7.6</span> Exposing Services To External Clients</h4>
<div class="outline-text-4" id="text-1-7-6">
<p>
A few ways to make a service accessible externally:
</p>

<ol class="org-ol">
<li>Setting the service type to NodePort</li>
<li>Setting the service type to LoadBalancer, an extension of the NodePort type</li>
<li>Creating an Ingress resource</li>
</ol>
</div>

<div id="outline-container-org35302b3" class="outline-5">
<h5 id="org35302b3"><span class="section-number-5">1.7.6.1</span> NodePort</h5>
<div class="outline-text-5" id="text-1-7-6-1">

<div class="figure">
<p><img src="img/k8s_svc_node_port_overall.png" alt="k8s_svc_node_port_overall.png">
</p>
</div>

<p>
An incoming connection to one of those ports will be redirected to a randomly selected pod, <br>
which may or may not be the one running on the node the connection is being made to.
</p>

<pre class="example">
If you only point your clients to the first node, when that node fails, your clients can't access the service anymore.
That's why it makes sense to put a load balancer in front of the nodes to make sure you're spreading requests across all healthy nodes and never sending them to a node that's offline at that moment.
</pre>
</div>

<div id="outline-container-orgdd2097a" class="outline-6">
<h6 id="orgdd2097a"><span class="section-number-6">1.7.6.1.1</span> YAML Definition</h6>
<div class="outline-text-6" id="text-1-7-6-1-1">

<div class="figure">
<p><img src="img/k8s_svc_node_port_def.png" alt="k8s_svc_node_port_def.png">
</p>
</div>

<pre class="example">
Specifying the port isn't mandatory; Kubernetes will choose a random port if you omit it.
</pre>
</div>
</div>
</div>



<div id="outline-container-org23fb929" class="outline-5">
<h5 id="org23fb929"><span class="section-number-5">1.7.6.2</span> LoadBalancer</h5>
<div class="outline-text-5" id="text-1-7-6-2">
<p>
Kubernetes clusters running on cloud providers usually support the automatic provision of a load balancer from the cloud infrastructure. <br>
The load balancer will have its own unique, publicly accessible IP address and will redirect all connections to your service. <br>
You can thus access your service through the load balancer's IP address.
</p>

<p>
If Kubernetes is running in an environment that doesn't support LoadBalancer services, <br>
the load balancer will not be provisioned, but the service will still behave like a NodePort service. <br>
That's because <b>a LoadBalancer service is an extension of a NodePort service.</b> <br>
(LoadBalancer type service is still a NodePort service but with an additional infrastructure-provided load balancer)
</p>



<div class="figure">
<p><img src="img/k8s_svc_lb_overall.png" alt="k8s_svc_lb_overall.png">
</p>
</div>
</div>


<div id="outline-container-orgc60c6b5" class="outline-6">
<h6 id="orgc60c6b5"><span class="section-number-6">1.7.6.2.1</span> YAML Definition</h6>
<div class="outline-text-6" id="text-1-7-6-2-1">

<div class="figure">
<p><img src="img/k8s_svc_lb_def.png" alt="k8s_svc_lb_def.png">
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org7a8744f" class="outline-5">
<h5 id="org7a8744f"><span class="section-number-5">1.7.6.3</span> Ingress</h5>
<div class="outline-text-5" id="text-1-7-6-3">
<p>
One important reason is that each LoadBalancer service requires its own load balancer with its own public IP address, <br>
whereas an Ingress <b>only requires one</b>, even when providing access to dozens of services.
</p>

<p>
Ingresses operate at the application layer of the network stack (HTTP) and can provide features such as cookie-based session affinity and the like, <br>
which services can’t.
</p>



<div class="figure">
<p><img src="img/k8s_svc_ingress_overall.png" alt="k8s_svc_ingress_overall.png">
</p>
</div>

<pre class="example">
Ingress controller provisions a load balancer behind the scenes.
</pre>
</div>


<div id="outline-container-org6ccb222" class="outline-6">
<h6 id="org6ccb222"><span class="section-number-6">1.7.6.3.1</span> YAML Definition</h6>
<div class="outline-text-6" id="text-1-7-6-3-1">

<div class="figure">
<p><img src="img/k8s_svc_ingress_def.png" alt="k8s_svc_ingress_def.png">
</p>
</div>


<div class="figure">
<p><img src="img/k8s_svc_ingress_process.png" alt="k8s_svc_ingress_process.png">
</p>
</div>


<p>
Ingress controller didn’t forward the request to the service. <b>It only used it to select a pod</b>. (Most controllers work like this)
</p>
</div>
</div>
</div>
</div>



<div id="outline-container-orgee8c5ce" class="outline-4">
<h4 id="orgee8c5ce"><span class="section-number-4">1.7.7</span> Readiness Probe</h4>
<div class="outline-text-4" id="text-1-7-7">
<p>
Kubernetes invokes the probe periodically and acts based on the result of the readiness probe. <br>
If a pod reports that it’s not ready, it’s removed from the service. If the pod then becomes ready again, it’s re-added.
</p>

<p>
Unlike liveness probes, if a container fails the readiness check, it won’t be killed or restarted. <br>
The effect is the same as when the pod doesn’t match the service’s label selector at all:
</p>


<div class="figure">
<p><img src="img/k8s_svc_readiness_probe.png" alt="k8s_svc_readiness_probe.png">
</p>
</div>
</div>
</div>


<div id="outline-container-org2b76edb" class="outline-4">
<h4 id="org2b76edb"><span class="section-number-4">1.7.8</span> Headless</h4>
<div class="outline-text-4" id="text-1-7-8">
<p>
Kubernetes allows clients to <b>discover pod IPs</b> through DNS lookups. <br>
Usually, when you perform a DNS lookup for a service, the DNS server returns a single IP (the service’s cluster IP). <br>
By setting the <code>clusterIP</code> field to <code>None</code> in the service specification, the DNS server will return the pod IPs instead of the single service IP.
</p>

<p>
Instead of returning a single DNS A record, the DNS server will return multiple A records for the service, <br>
each pointing to the IP of an individual pod backing the service at that moment.
</p>

<pre class="example">
A headless services still provides load balancing across pods,
but through the DNS round-robin mechanism instead of through the service proxy.
</pre>
</div>
</div>

<div id="outline-container-org5339ec8" class="outline-4">
<h4 id="org5339ec8"><span class="section-number-4">1.7.9</span> External Traffic Issue</h4>
<div class="outline-text-4" id="text-1-7-9">
<p>
When an external client connects to a service through the node port (this also includes cases when it goes through the load balancer first), <br>
the randomly chosen pod may or may not be running on the same node that received the connection. <br>
An additional network hop is required to reach the pod, but this may not always be desirable.
</p>

<p>
You can prevent this additional hop by configuring the service to redirect external traffic only to pods running on the node that received the connection. <br>
This is done by setting the <code>externalTrafficPolicy</code> field in the service's spec section:
</p>

<div class="org-src-container">
<pre class="src src-yaml">spec:
  externalTrafficPolicy: Local
  ...
</pre>
</div>

<p>
f a service definition includes this setting and an external connection is opened through the service's node port, <br>
the service proxy will choose a locally running pod. If no local pods exist, the connection will <b>hang</b>. <br>
You therefore need to ensure the load balancer forwards connections only to nodes that <b>have at least one such pod</b>.
</p>
</div>

<div id="outline-container-org9d29310" class="outline-5">
<h5 id="org9d29310"><span class="section-number-5">1.7.9.1</span> Non-Preservation Of The Client's IP Issue</h5>
<div class="outline-text-5" id="text-1-7-9-1">
<p>
Usually, when clients inside the cluster connect to a service, the pods backing the service <b>can obtain the client's IP address</b>. <br>
But when the connection is received through a node port, the packets' <b>source IP is changed</b>, because SNAT is performed on the packets.
</p>

<p>
The <span class="underline">Local</span> external traffic policy (externalTrafficPolicy: Local) described in the previous section affects the preservation of the client's IP, <br>
because there's no additional hop between the node receiving the connection and the node hosting the target pod (<b>SNAT isn't performed</b>).
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orge3e3ca0" class="outline-3">
<h3 id="orge3e3ca0"><span class="section-number-3">1.8</span> Volume</h3>
<div class="outline-text-3" id="text-1-8">
<p>
Volumes aren't top-level resources like pods, but are instead defined as <b>a part of a pod</b> and <b>share the same lifecycle as the pod.</b> <br>
This means <span class="underline">a volume is created when the pod is started and is destroyed when the pod is deleted.</span>
</p>

<pre class="example">
Kubernetes volumes are a component of a pod and are thus defined in the pod's specification-much like containers.
They aren't a standalone Kubernetes object and can not be created or deleted on their own.
</pre>


<div class="figure">
<p><img src="img/k8s_vol.png" alt="k8s_vol.png">
</p>
</div>
</div>

<div id="outline-container-org26f730b" class="outline-4">
<h4 id="org26f730b"><span class="section-number-4">1.8.1</span> Volume Types</h4>
<div class="outline-text-4" id="text-1-8-1">
<dl class="org-dl">
<dt>emptyDir</dt><dd>A simple empty directory used for storing transient data.</dd>
<dt>hostPath</dt><dd>Used for mounting directories from the worker node's filesystem into the pod.</dd>
<dt>gitRepo</dt><dd>A volume initialized by checking out the contents of a Git repository.</dd>
<dt>nfs</dt><dd>An NFS share mounted into the pod.</dd>
<dt>gcePersistentDisk, awsElasticBlockStore, azureDisk</dt><dd>Cloud provider.</dd>
<dt>cinder, cephfs, iscsi, flocker, glusterfs, quobyte, rbd, flexVolume, vsphere- Volume, photonPersistentDisk, scaleIO</dt><dd>Network storage.</dd>
<dt>configMap, secret, downwardAPI</dt><dd></dd>

<dt>persistentVolumeClaim</dt><dd></dd>
</dl>
</div>
</div>


<div id="outline-container-org614a798" class="outline-4">
<h4 id="org614a798"><span class="section-number-4">1.8.2</span> emptyDir</h4>
<div class="outline-text-4" id="text-1-8-2">
<p>
An <code>emptyDir</code> volume is especially useful for sharing files between containers running in the same pod.
</p>

<p>
An <code>emptyDir</code> volume is the simplest type of volume, but <b>other types build upon it</b>. (After the empty directory is created, they then populate it with data)
</p>


<div class="figure">
<p><img src="img/k8s_vol_empty_def.png" alt="k8s_vol_empty_def.png">
</p>
</div>
</div>





<div id="outline-container-org663c602" class="outline-5">
<h5 id="org663c602"><span class="section-number-5">1.8.2.1</span> The medium used</h5>
<div class="outline-text-5" id="text-1-8-2-1">
<p>
The <code>emptyDir</code> used as the volume was created on the actual disk of the worker node hosting the pod. <br>
Kubernetes can create the <code>emptyDir</code> on a tmpfs filesystem (in memory instead of on disk). <br>
To do this, set the <code>emptyDir</code>'s medium to <code>Memory</code>:
</p>

<div class="org-src-container">
<pre class="src src-yaml">volumes:
  - name: html
    emptyDir:
      medium: Memory
</pre>
</div>
</div>
</div>
</div>












<div id="outline-container-orgfb134c3" class="outline-4">
<h4 id="orgfb134c3"><span class="section-number-4">1.8.3</span> hostPath</h4>
<div class="outline-text-4" id="text-1-8-3">

<div class="figure">
<p><img src="img/k8s_vol_host.png" alt="k8s_vol_host.png">
</p>
</div>

<p>
It’s not a good idea to use a hostPath volume for regular pods, because it makes the pod sensitive to what node it’s scheduled to.
</p>

<pre class="example">
Remember to use hostPath volumes only if you need to read or write system files on the node. Never use them to persist data across pods.
</pre>
</div>
</div>



<div id="outline-container-orgf5e2324" class="outline-4">
<h4 id="orgf5e2324"><span class="section-number-4">1.8.4</span> PV/PVC</h4>
<div class="outline-text-4" id="text-1-8-4">

<div class="figure">
<p><img src="img/k8s_vol_pv_pvc.png" alt="k8s_vol_pv_pvc.png">
</p>
</div>


<p>
Instead of the developer adding a technology-specific volume to their pod, it’s the <b>cluster administrator</b> who sets up the underlying storage and then <br>
registers it in Kubernetes by creating a PersistentVolume resource through the Kubernetes API server.
</p>

<p>
When a cluster user needs to use persistent storage in one of their pods, they first create a PersistentVolumeClaim manifest,
specifying the minimum size and the access mode they require. <br>
The user then submits the PersistentVolumeClaim manifest to the Kubernetes API server,
and Kubernetes finds the appropriate PersistentVolume and <b>binds the volume to the claim.</b> <br>
The PersistentVolumeClaim can then be used as one of the volumes inside a pod.
</p>

<pre class="example">
Other users cannot use the same PersistentVolume until it has been released by delet- ing the bound PersistentVolumeClaim.
</pre>
</div>

<div id="outline-container-orgc5cfebd" class="outline-5">
<h5 id="orgc5cfebd"><span class="section-number-5">1.8.4.1</span> Creating PersistentVolume</h5>
<div class="outline-text-5" id="text-1-8-4-1">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: mongodb-pv
spec:
  capacity:
    storage: 1Gi                # Defining the PersistentVolume's size
  accessModes:                  # Cwhether it can be read from and/or written to by a single node or by multiple nodes at the same time.
    - ReadWriteOnce
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain # After the claim is released, the PersistentVolume should be retained (not erased or deleted).
                                        # Have to manually delete pv when it is no more needed. (no deleted when pvc is deleted)
  hostPath:
    path: /tmp/mongodb
</pre>
</div>

<pre class="example">
PersistentVolumes don’t belong to any namespace. They’re cluster-level resources like nodes.
</pre>

<p>
(<b>注:</b> <code>spec.capacity.storage</code> 看起来只是用于匹配 PVC ，实际容量应以 Actual storage 为准)
</p>


<div class="figure">
<p><img src="img/k8s_vol_pv_pvc_overall.png" alt="k8s_vol_pv_pvc_overall.png">
</p>
</div>
</div>


<div id="outline-container-org5922ed4" class="outline-6">
<h6 id="org5922ed4"><span class="section-number-6">1.8.4.1.1</span> Access Mode</h6>
<div class="outline-text-6" id="text-1-8-4-1-1">
<dl class="org-dl">
<dt>ReadWriteOnce</dt><dd>Only a single node can mount the volume for reading and writing.</dd>
<dt>ReadOnlyMany</dt><dd>Multiple nodes can mount the volume for reading.</dd>
<dt>ReadWriteMany</dt><dd>Multiple nodes can mount the volume for both reading and writing.</dd>
</dl>

<pre class="example">
RWO, ROX, and RWX pertain to the number of worker nodes that can use the volume at the same time, not to the number of pods!
</pre>
</div>
</div>
</div>




<div id="outline-container-org4ff9bb2" class="outline-5">
<h5 id="org4ff9bb2"><span class="section-number-5">1.8.4.2</span> Creating PersistentVolumeClaim</h5>
<div class="outline-text-5" id="text-1-8-4-2">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  resources:
    requests:
      storage: 1Gi
  accessModes:
  - ReadWriteOnce
  storageClassName: ""  # Specifying an empty string as the storage class name ensures the PVC binds to a pre-provisioned PV instead of dynamically provisioning a new one.
</pre>
</div>


<p>
As soon as you create the claim, Kubernetes finds the appropriate PersistentVolume and binds it to the claim. <br>
The PersistentVolume’s capacity must be <b>large enough</b> to accommodate what the claim requests.
Additionally, the volume’s access modes must <b>include</b> the access modes requested by the claim.
</p>
</div>
</div>


<div id="outline-container-org035df15" class="outline-5">
<h5 id="org035df15"><span class="section-number-5">1.8.4.3</span> Using PersistentVolumeClaim in Pod</h5>
<div class="outline-text-5" id="text-1-8-4-3">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Pod
metadata:
  name: mongodb
spec:
  containers:
  - image: mongo
    name: mongodb
    volumeMounts:
    - name: mongodb-data
      mountPath: /data/db
    ports:
    - containerPort: 27017
      protocol: TCP
  volumes:
  - name: mongodb-data
    persistentVolumeClaim:
      claimName: mongodb-pvc    # referenced by name

</pre>
</div>



<div class="figure">
<p><img src="img/k8s_vol_pv_pvc_logic.png" alt="k8s_vol_pv_pvc_logic.png">
</p>
</div>
</div>
</div>


<div id="outline-container-org9994bbd" class="outline-5">
<h5 id="org9994bbd"><span class="section-number-5">1.8.4.4</span> Dynamic Provisioning of PV</h5>
<div class="outline-text-5" id="text-1-8-4-4">
<p>
Cluster administrator can define <code>StorageClass</code> and let the system create a new PersistentVolume <b>each time</b> one is requested through a PersistentVolumeClaim.
</p>

<pre class="example">
Similar to PersistentVolumes, StorageClass resources aren’t namespaced.
</pre>


<div class="figure">
<p><img src="img/k8s_vol_pv_dp.png" alt="k8s_vol_pv_dp.png">
</p>
</div>
</div>

<div id="outline-container-org72c3984" class="outline-6">
<h6 id="org72c3984"><span class="section-number-6">1.8.4.4.1</span> Defining StorageClass</h6>
<div class="outline-text-6" id="text-1-8-4-4-1">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast
provisioner: k8s.io/minikube-hostpath # The volume plugin to use for provisioning the PersistentVolume
parameters:                           # Parameterd passed to the provisioner
  type: pd-ssd
</pre>
</div>
</div>
</div>


<div id="outline-container-orgec595b2" class="outline-6">
<h6 id="orgec595b2"><span class="section-number-6">1.8.4.4.2</span> Requesting the SC in a PVC</h6>
<div class="outline-text-6" id="text-1-8-4-4-2">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  storageClassName: fast
  resources:
    requests:
      storage: 100Mi
  accessModes:
    - ReadWriteOnce
</pre>
</div>

<pre class="example">
The provisioner is used even if an existing manually provisioned PersistentVolume matches the PersistentVolumeClaim.
</pre>
</div>
</div>


<div id="outline-container-orgd63ec53" class="outline-6">
<h6 id="orgd63ec53"><span class="section-number-6">1.8.4.4.3</span> Creating a PVC Without SC</h6>
<div class="outline-text-6" id="text-1-8-4-4-3">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc2
spec:
  resources:
    requests:
      storage: 100Mi
  accessModes:
    - ReadWriteOnce
</pre>
</div>

<pre class="example">
The default storage class is what's used to dynamically provision a PersistentVolume if the PersistentVolumeClaim doesn't explicitly say which storage class to use.
</pre>
</div>
</div>




<div id="outline-container-org6015e18" class="outline-6">
<h6 id="org6015e18"><span class="section-number-6">1.8.4.4.4</span> Forcing a PVC to Be Bound to One of The Pre-Provisioned PVs</h6>
<div class="outline-text-6" id="text-1-8-4-4-4">
<pre class="example">
Explicitly set storageClassName to "" if you want the PVC to use a pre-provisioned PersistentVolume.
</pre>
</div>
</div>
</div>
</div>
</div>






<div id="outline-container-orged13786" class="outline-3">
<h3 id="orged13786"><span class="section-number-3">1.9</span> ConfigMap &amp; Secret</h3>
<div class="outline-text-3" id="text-1-9">
</div>
<div id="outline-container-org8b5fea1" class="outline-4">
<h4 id="org8b5fea1"><span class="section-number-4">1.9.1</span> Basic</h4>
<div class="outline-text-4" id="text-1-9-1">
</div>
<div id="outline-container-org59339d3" class="outline-5">
<h5 id="org59339d3"><span class="section-number-5">1.9.1.1</span> Overriding the command and arguments</h5>
<div class="outline-text-5" id="text-1-9-1-1">
<p>
In Kubernetes, when specifying a container, you can choose to override both <code>ENTRYPOINT</code> and <code>CMD</code>.
</p>


<div class="figure">
<p><img src="img/k8s_config_overriding.png" alt="k8s_config_overriding.png">
</p>
</div>


<p>
In most cases, you’ll only set custom arguments and rarely override the command
(except in <b>general-purpose images such as busybox</b>, which doesn’t define an <code>ENTRYPOINT</code> at all).
</p>

<pre class="example">
The command and args fields can’t be updated after the pod is created.
</pre>
</div>
</div>


<div id="outline-container-org875d26c" class="outline-5">
<h5 id="org875d26c"><span class="section-number-5">1.9.1.2</span> Specifing env variables</h5>
<div class="outline-text-5" id="text-1-9-1-2">
<div class="org-src-container">
<pre class="src src-yaml">kind: Pod
spec:
 containers:
 - image: luksa/fortune:env
   env:                         # Adding a single variable to the environment variable list
   - name: INTERVAL
     value: "30"
   name: html-generator
</pre>
</div>

<div class="org-src-container">
<pre class="src src-yaml">env:
- name: FIRST_VAR
  value: "foo"
- name: SECOND_VAR
  value: "$(FIRST_VAR)bar"      # Referring to other environment variables
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org21d270f" class="outline-4">
<h4 id="org21d270f"><span class="section-number-4">1.9.2</span> ConfigMap</h4>
<div class="outline-text-4" id="text-1-9-2">

<div class="figure">
<p><img src="img/k8s_config_map.png" alt="k8s_config_map.png">
</p>
</div>
</div>


<div id="outline-container-org31a4d6d" class="outline-5">
<h5 id="org31a4d6d"><span class="section-number-5">1.9.2.1</span> Creating</h5>
<div class="outline-text-5" id="text-1-9-2-1">
</div>
<div id="outline-container-org46319aa" class="outline-6">
<h6 id="org46319aa"><span class="section-number-6">1.9.2.1.1</span> CLI</h6>
<div class="outline-text-6" id="text-1-9-2-1-1">
<div class="org-src-container">
<pre class="src src-sh">kubectl create configmap my-config <span style="color: #e6db74;">\</span>
        --from-file=foo.json <span style="color: #e6db74;">\ </span> <span style="color: #465457;"># </span><span style="color: #465457;">A single file</span>
        --from-file=<span style="color: #fd971f;">bar</span>=foobar.conf <span style="color: #e6db74;">\ </span><span style="color: #465457;"># </span><span style="color: #465457;">A file stored under a custom key</span>
        --from-file=config-opts/ <span style="color: #e6db74;">\ </span>A whole directory
        --from-literal=<span style="color: #fd971f;">some</span>=thing <span style="color: #465457;"># </span><span style="color: #465457;">A literal value</span>
</pre>
</div>



<div class="figure">
<p><img src="img/k8s_config_map_cli.png" alt="k8s_config_map_cli.png">
</p>
</div>
</div>
</div>



<div id="outline-container-orgc676fba" class="outline-6">
<h6 id="orgc676fba"><span class="section-number-6">1.9.2.1.2</span> YAML</h6>
<div class="outline-text-6" id="text-1-9-2-1-2">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: fortune-config
data:
  sleep-interval: "25"
</pre>
</div>
</div>
</div>
</div>




<div id="outline-container-org794219f" class="outline-5">
<h5 id="org794219f"><span class="section-number-5">1.9.2.2</span> Passing CM to Container</h5>
<div class="outline-text-5" id="text-1-9-2-2">
</div>
<div id="outline-container-org32501df" class="outline-6">
<h6 id="org32501df"><span class="section-number-6">1.9.2.2.1</span> As ENV</h6>
<div class="outline-text-6" id="text-1-9-2-2-1">

<div class="figure">
<p><img src="img/k8s_config_map_env.png" alt="k8s_config_map_env.png">
</p>
</div>

<ul class="org-ul">
<li><p>
Passing all entries of a ConfigMap as environment variables at once
</p>

<div class="org-src-container">
<pre class="src src-yaml">spec:
  containers:
  - image: some-image
    envFrom:                    # Using envFrom instead of env
    - prefix: CONFIG_           # All environment variables will be prefixed with CONFIG_.
      configMapRef:
        name: my-config-map     # Referencing the ConfigMap called my-config-map

</pre>
</div></li>
</ul>

<pre class="example">
The prefix is optional, so if you omit it the environment variables will have the same name as the keys.
</pre>

<ul class="org-ul">
<li><p>
Passing a ConfigMap entry as a command-line argument
</p>

<p>
You can’t reference ConfigMap entries directly in the <code>pod.spec.containers.args</code> field,
but you can first initialize an environment variable from the ConfigMap entry and then refer to the variable inside the arguments:
</p>


<div class="figure">
<p><img src="img/k8s_config_map_env_args.png" alt="k8s_config_map_env_args.png">
</p>
</div></li>
</ul>
</div>
</div>




<div id="outline-container-org0b0382f" class="outline-6">
<h6 id="org0b0382f"><span class="section-number-6">1.9.2.2.2</span> As Volume</h6>
<div class="outline-text-6" id="text-1-9-2-2-2">
<p>
A <code>configMap</code> volume will expose each entry of the ConfigMap <b>as a file.</b>
The process running in the container can obtain the entry’s value by reading the contents of the file.
</p>


<div class="figure">
<p><img src="img/k8s_config_map_vol_yaml.png" alt="k8s_config_map_vol_yaml.png">
</p>
</div>


<div class="figure">
<p><img src="img/k8s_config_map_vol.png" alt="k8s_config_map_vol.png">
</p>
</div>


<ul class="org-ul">
<li><p>
Exposing Certain ConfigMap Entries in the Volume
</p>


<div class="figure">
<p><img src="img/k8s_config_map_vol_with_items.png" alt="k8s_config_map_vol_with_items.png">
</p>
</div></li>
</ul>


<ul class="org-ul">
<li><p>
Mounting Individual ConfigMap Entries as Files without Hiding Other Files in the Directory
</p>


<div class="figure">
<p><img src="img/k8s_config_map_vol_with_specific_items.png" alt="k8s_config_map_vol_with_specific_items.png">
</p>
</div>


<div class="figure">
<p><img src="img/k8s_config_map_vol_with_specific_items_pic.png" alt="k8s_config_map_vol_with_specific_items_pic.png">
</p>
</div></li>
</ul>


<pre class="example">
The 'subPath' property can be used when mounting any kind of volume. Instead of mounting the whole volume, you can mount part of it.
</pre>




<ul class="org-ul">
<li><p>
Setting the File Permissions for Files in a ConfigMap Volume
</p>

<div class="org-src-container">
<pre class="src src-yaml">volumes:
- name: config
  configMap:
    name: fortune-config
    defaultMode: "6600"         # This sets the permissions for all files to -rw-rw------
</pre>
</div></li>
</ul>
</div>
</div>
</div>
</div>


<div id="outline-container-orged8bd86" class="outline-4">
<h4 id="orged8bd86"><span class="section-number-4">1.9.3</span> Secret</h4>
<div class="outline-text-4" id="text-1-9-3">
<p>
Kubernetes helps keep your Secrets safe by making sure each Secret <b>is only distributed to the nodes</b> that run the pods that need access to the Secret. <br>
Also, on the nodes themselves, Secrets are always <b>stored in memory and never written to physical storage.</b>
</p>
</div>


<div id="outline-container-orgefff64c" class="outline-5">
<h5 id="orgefff64c"><span class="section-number-5">1.9.3.1</span> Default Token Secret</h5>
<div class="outline-text-5" id="text-1-9-3-1">
<p>
<b>Every pod has a secret volume</b> attached to it automatically, which represent everything you need to securely talk to the Kubernetes API server from within your pods, should you need to do that.
</p>

<pre class="example">
By default, the default-token Secret is mounted into every container, but you can disable that in each pod
by setting the automountServiceAccountToken field in the pod spec to false or by setting it to false on the service account the pod is using.
</pre>



<div class="figure">
<p><img src="img/k8s_secret_default_token.png" alt="k8s_secret_default_token.png">
</p>
</div>
</div>
</div>
</div>
</div>
</div>




<div id="outline-container-org42ab15e" class="outline-2">
<h2 id="org42ab15e"><span class="section-number-2">2</span> Internals</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orga060833" class="outline-3">
<h3 id="orga060833"><span class="section-number-3">2.1</span> Container Vs VM</h3>
<div class="outline-text-3" id="text-2-1">

<div class="figure">
<p><img src="img/k8s_container_vs_vm.png" alt="k8s_container_vs_vm.png">
</p>
</div>


<div class="figure">
<p><img src="img/k8s_container_vs_vm_cpu.png" alt="k8s_container_vs_vm_cpu.png">
</p>
</div>
</div>
</div>


<div id="outline-container-orge454b97" class="outline-3">
<h3 id="orge454b97"><span class="section-number-3">2.2</span> K8S components</h3>
<div class="outline-text-3" id="text-2-2">

<div class="figure">
<p><img src="img/k8s_components.png" alt="k8s_components.png">
</p>
</div>
</div>
</div>
</div>








































<div id="outline-container-org3c1319a" class="outline-2">
<h2 id="org3c1319a"><span class="section-number-2">3</span> YAML</h2>
<div class="outline-text-2" id="text-3">
<p>
<a href="https://plugins.jetbrains.com/plugin/9354-kubernetes-and-openshift-resource-support">IDEA Kubernetes YAML 插件</a>
</p>
</div>

<div id="outline-container-org88b286f" class="outline-3">
<h3 id="org88b286f"><span class="section-number-3">3.1</span> Key Value Pair</h3>
<div class="outline-text-3" id="text-3-1">
<div class="org-src-container">
<pre class="src src-yaml">fruit: apple
vegetable: carrot
liquid: water
meat: chicken
</pre>
</div>
</div>
</div>


<div id="outline-container-org76f40c1" class="outline-3">
<h3 id="org76f40c1"><span class="section-number-3">3.2</span> Array / List</h3>
<div class="outline-text-3" id="text-3-2">
<div class="org-src-container">
<pre class="src src-yaml">fruits:
  - orange
  - apple
  - banana

vegetables:
  - carrot
  - cauliflower
  - tomato
</pre>
</div>
</div>
</div>


<div id="outline-container-orgf1e057d" class="outline-3">
<h3 id="orgf1e057d"><span class="section-number-3">3.3</span> Dictionary / Map</h3>
<div class="outline-text-3" id="text-3-3">
<div class="org-src-container">
<pre class="src src-yaml">banana:
  calories: 105
  fat: 0.4
  carbs: 27

grape:
  calories: 62
  fat: 0.3
  carbs: 16
</pre>
</div>
</div>
</div>
</div>



<div id="outline-container-orge11b396" class="outline-2">
<h2 id="orge11b396"><span class="section-number-2">4</span> 核心原理</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orgc57e234" class="outline-3">
<h3 id="orgc57e234"><span class="section-number-3">4.1</span> 资源对象</h3>
<div class="outline-text-3" id="text-4-1">
</div>
<div id="outline-container-org56d639b" class="outline-4">
<h4 id="org56d639b"><span class="section-number-4">4.1.1</span> POD</h4>
<div class="outline-text-4" id="text-4-1-1">
</div>
<div id="outline-container-org840afb9" class="outline-5">
<h5 id="org840afb9"><span class="section-number-5">4.1.1.1</span> 基本 YAML 定义</h5>
<div class="outline-text-5" id="text-4-1-1-1">
<p>
<b>apiVersion, kind, metadata, spec 是必填项</b>
</p>

<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
</pre>
</div>






<div class="org-src-container">
<pre class="src src-sh">kubectl get pods
kubectl describe pod &lt;pod_name&gt;
</pre>
</div>
</div>
</div>



<div id="outline-container-org8475f92" class="outline-5">
<h5 id="org8475f92"><span class="section-number-5">4.1.1.2</span> 设计理念</h5>
<div class="outline-text-5" id="text-4-1-1-2">
<p>
Pod 是在 K8s 集群中运行部署应用或服务的最小单元，它是可以支持多容器的。
</p>

<p>
Pod 的设计理念是支持多个容器在一个 Pod 中共享网络地址和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。
</p>

<p>
Pod 是 K8s 集群中所有业务类型的基础，不同类型的业务就需要不同类型的 <b>控制器</b> 去执行。
</p>

<p>
目前 K8s 中的业务主要可以分为：
</p>

<ul class="org-ul">
<li>长期伺服型 (long-running)</li>
<li>批处理型 (batch)</li>
<li>节点后台支撑型 (node-daemon)</li>
<li>有状态应用型 (stateful application)</li>
</ul>

<p>
分别对应的控制器类型为：
</p>

<ul class="org-ul">
<li>Deployment</li>
<li>Job</li>
<li>DaemonSet</li>
<li>StatefulSet</li>
</ul>

<p>
直接创建的 Pod 一旦被调度后就跟 Node 绑定，即使 Node 挂掉也不会被重新调度（ <b>而是被自动删除</b> ），因此推荐使用 Deployment、Daemonset 等控制器来容错。
</p>
</div>
</div>



<div id="outline-container-org610d487" class="outline-5">
<h5 id="org610d487"><span class="section-number-5">4.1.1.3</span> 生命周期</h5>
<div class="outline-text-5" id="text-4-1-1-3">
<dl class="org-dl">
<dt>Pending</dt><dd>Pod 已经在 apiserver 中创建，但还没有调度到 Node 上面</dd>
<dt>Running</dt><dd>Pod 已经调度到 Node 上面，所有容器都已经创建，并且至少有一个容器还在运行或者正在启动</dd>
<dt>Succeeded</dt><dd>Pod 调度到 Node 上面后成功运行结束，并且不会重启</dd>
<dt>Failed</dt><dd>Pod 调度到 Node 上面后至少有一个容器运行失败（即退出码不为 0 或者被系统终止）</dd>
<dt>Unknonwn</dt><dd>状态未知，通常是由于 apiserver 无法与 kubelet 通信导致</dd>
</dl>
</div>
</div>



<div id="outline-container-org43137be" class="outline-5">
<h5 id="org43137be"><span class="section-number-5">4.1.1.4</span> 重启策略(restartPolicy)</h5>
<div class="outline-text-5" id="text-4-1-1-4">
<p>
PodSpec 中的 <code>restartPolicy</code> 可以用来设置是否对退出的 Pod 重启，可选项包括:
</p>

<dl class="org-dl">
<dt>Always</dt><dd>只要退出就重启</dd>
<dt>OnFailure</dt><dd>失败退出（exit code 不等于 0）时重启</dd>
<dt>Never</dt><dd>只要退出就不再重启</dd>
</dl>

<p>
<b>注意，这里的重启是指在 Pod 所在 Node 上面本地重启，并不会调度到其他 Node 上去。</b>
</p>

<ul class="org-ul">
<li>单容器的 Pod ，容器成功退出时，不同 restartPolicy 时的动作为
<ul class="org-ul">
<li>Always: 重启 Container; Pod phase 保持 Running.</li>
<li>OnFailure: Pod phase 变成 Succeeded.</li>
<li>Never: Pod phase 变成 Succeeded.</li>
</ul></li>

<li>单容器的 Pod ，容器失败退出时，不同 restartPolicy 时的动作为
<ul class="org-ul">
<li>Always: 重启 Container; Pod phase 保持 Running.</li>
<li>OnFailure: 重启 Container; Pod phase 保持 Running.</li>
<li>Never: Pod phase 变成 Failed.</li>
</ul></li>

<li>2 个容器的 Pod，其中一个容器在运行而另一个失败退出时，不同 restartPolicy 时的动作为
<ul class="org-ul">
<li>Always: 重启 Container; Pod phase 保持 Running.</li>
<li>OnFailure: 重启 Container; Pod phase 保持 Running.</li>
<li>Never: 不重启 Container; Pod phase 保持 Running.</li>
</ul></li>

<li>2 个容器的 Pod，其中一个容器停止而另一个失败退出时，不同 restartPolicy 时的动作为
<ul class="org-ul">
<li>Always: 重启 Container; Pod phase 保持 Running.</li>
<li>OnFailure: 重启 Container; Pod phase 保持 Running.</li>
<li>Never: Pod phase 变成 Failed.</li>
</ul></li>

<li>单容器的 Pod，容器内存不足（OOM），不同 restartPolicy 时的动作为
<ul class="org-ul">
<li>Always: 重启 Container; Pod phase 保持 Running.</li>
<li>OnFailure: 重启 Container; Pod phase 保持 Running.</li>
<li>Never: 记录失败事件; Pod phase 变成 Failed.</li>
</ul></li>
</ul>

<p>
其他情况的处理逻辑：
</p>

<ul class="org-ul">
<li>Pod 还在运行，但磁盘不可访问时
<ol class="org-ol">
<li>终止所有容器</li>
<li>Pod phase 变成 Failed</li>
<li>如果 Pod 是由某个控制器管理的，则重新创建一个 Pod 并调度到其他 Node 运行</li>
</ol></li>

<li>Pod 还在运行，但由于网络分区故障导致 Node 无法访问
<ol class="org-ol">
<li>Node controller等待 Node 事件超时</li>
<li>Node controller 将 Pod phase 设置为 Failed.</li>
<li>如果 Pod 是由某个控制器管理的，则重新创建一个 Pod 并调度到其他 Node 运行</li>
</ol></li>
</ul>
</div>
</div>




<div id="outline-container-orga07e02d" class="outline-5">
<h5 id="orga07e02d"><span class="section-number-5">4.1.1.5</span> 使用 Volume</h5>
<div class="outline-text-5" id="text-4-1-1-5">
<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: redis-storage
      mountPath: /data/redis
  volumes:
  - name: redis-storage
    emptyDir: {}

</pre>
</div>
</div>
</div>



<div id="outline-container-org89c3604" class="outline-5">
<h5 id="org89c3604"><span class="section-number-5">4.1.1.6</span> 环境变量</h5>
<div class="outline-text-5" id="text-4-1-1-6">
<p>
Pod 的名字、命名空间、IP 以及容器的计算资源限制等可以通过 <a href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">Downward API</a> 的方式获取并存储到环境变量中。
</p>
</div>
</div>



<div id="outline-container-org4a80b4e" class="outline-5">
<h5 id="org4a80b4e"><span class="section-number-5">4.1.1.7</span> 镜像拉取策略(ImagePullPolicy)</h5>
<div class="outline-text-5" id="text-4-1-1-7">
<p>
支持三种 <code>ImagePullPolicy</code>:
</p>

<dl class="org-dl">
<dt>Always</dt><dd>不管镜像是否存在都会进行一次拉取</dd>
<dt>Never</dt><dd>不管镜像是否存在都不会进行拉取</dd>
<dt>IfNotPresent</dt><dd>只有镜像不存在时，才会进行镜像拉取</dd>
</dl>

<p>
<b>注意：</b>
</p>

<p>
默认为 <code>IfNotPresent</code> ，但 :latest 标签的镜像默认为 <code>Always</code> 。
</p>

<p>
拉取镜像时 docker 会进行校验，如果镜像中的 MD5 码没有变，则不会拉取镜像数据。
</p>

<p>
生产环境中应该尽量避免使用 :latest 标签，而开发环境中可以借助 :latest 标签自动拉取最新的镜像。
</p>
</div>
</div>


<div id="outline-container-org0f108b0" class="outline-5">
<h5 id="org0f108b0"><span class="section-number-5">4.1.1.8</span> DNS 策略</h5>
<div class="outline-text-5" id="text-4-1-1-8">
<p>
通过设置 <code>dnsPolicy</code> 参数，设置 Pod 中容器访问 DNS 的策略：
</p>

<dl class="org-dl">
<dt>ClusterFirst</dt><dd>优先基于 cluster domain （如 default.svc.cluster.local） 后缀，通过 kube-dns 查询 (默认策略)</dd>
<dt>Default</dt><dd>优先从 Node 中配置的 DNS 查询</dd>
</dl>
</div>
</div>


<div id="outline-container-orge5f7d37" class="outline-5">
<h5 id="orge5f7d37"><span class="section-number-5">4.1.1.9</span> Health Probe</h5>
<div class="outline-text-5" id="text-4-1-1-9">
<p>
为了确保容器在部署后确实处在正常运行状态，Kubernetes 提供了两种探针（Probe）来探测容器的状态：
</p>

<dl class="org-dl">
<dt>LivenessProbe</dt><dd>探测应用是否处于健康状态，如果不健康则删除并重新创建容器</dd>
<dt>ReadinessProbe</dt><dd>探测应用是否启动完成并且处于正常服务状态，如果不正常则不会接收来自 Kubernetes Service 的流量</dd>
</dl>

<p>
Kubernetes 支持三种方式来执行探针：
</p>

<dl class="org-dl">
<dt>exec</dt><dd>在容器中执行一个命令，如果 命令退出码 返回 0 则表示探测成功，否则表示失败</dd>
<dt>tcpSocket</dt><dd>对指定的容器 IP 及端口执行一个 TCP 检查，如果端口是开放的则表示探测成功，否则表示失败</dd>
<dt>httpGet</dt><dd>对指定的容器 IP、端口及路径执行一个 HTTP Get 请求，如果返回的 状态码 在 [200,400) 之间则表示探测成功，否则表示失败</dd>
</dl>


<div class="org-src-container">
<pre class="src src-yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    app: nginx
  name: nginx
spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: http
      livenessProbe:
        httpGet:
          path: /
          port: 80
          httpHeaders:
          - name: X-Custom-Header
            value: Awesome
        initialDelaySeconds: 15
        timeoutSeconds: 1
      readinessProbe:
        exec:
          command:
          - cat
          - /usr/share/nginx/html/index.html
        initialDelaySeconds: 5
        timeoutSeconds: 1
    - name: goproxy
      image: gcr.io/google_containers/goproxy:0.1
      ports:
      - containerPort: 8080
      readinessProbe:
        tcpSocket:
          port: 8080
        initialDelaySeconds: 5
        periodSeconds: 10
      livenessProbe:
        tcpSocket:
          port: 8080
        initialDelaySeconds: 15
        periodSeconds: 20
</pre>
</div>
</div>
</div>


<div id="outline-container-org2d76219" class="outline-5">
<h5 id="org2d76219"><span class="section-number-5">4.1.1.10</span> 调度到指定 Node 上</h5>
<div class="outline-text-5" id="text-4-1-1-10">
<p>
可以通过 <code>nodeSelector</code>, <code>nodeAffinity</code>, <code>podAffinity</code> 以及 <code>Taints</code> 和 <code>tolerations</code> 等来将 Pod 调度到需要的 Node 上。
</p>

<pre class="example">
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    &lt;label&gt;: &lt;value&gt;
</pre>
</div>
</div>


<div id="outline-container-org36c011e" class="outline-5">
<h5 id="org36c011e"><span class="section-number-5">4.1.1.11</span> 常用命令</h5>
<div class="outline-text-5" id="text-4-1-1-11">
</div>
<div id="outline-container-org9fcff90" class="outline-6">
<h6 id="org9fcff90"><span class="section-number-6">4.1.1.11.1</span> 查看 Pod 状态</h6>
<div class="outline-text-6" id="text-4-1-1-11-1">
<p>
<code>kubectl get pod &lt;pod_name&gt; -o jsonpath</code>"{.status.phase}"=
</p>
</div>
</div>
</div>
</div>




<div id="outline-container-org383dc92" class="outline-4">
<h4 id="org383dc92"><span class="section-number-4">4.1.2</span> Replica Set</h4>
<div class="outline-text-4" id="text-4-1-2">
<p>
ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，
并且 ReplicaSet 支持集合式的 selector（ReplicationController 仅支持等式）。
</p>

<p>
Deployment 使用了 Replica Set ，是更高一层的概念。
除非需要自定义升级功能或根本不需要升级 Pod ，一般情况下，推荐使用 Deployment 而不直接使用 Replica Set 。
这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持 rolling-update 但 Deployment 支持），
并且还支持版本记录、回滚、暂停升级等高级特性。
</p>
</div>


<div id="outline-container-org44a468b" class="outline-5">
<h5 id="org44a468b"><span class="section-number-5">4.1.2.1</span> YAML 定义</h5>
<div class="outline-text-5" id="text-4-1-2-1">
<p>
<code>spec.template</code> 可以从 Pod 定义文件中复制过来：
</p>


<div class="figure">
<p><img src="img/k8s_replica-set-tmpl.png" alt="k8s_replica-set-tmpl.png">
</p>
</div>
</div>
</div>


<div id="outline-container-orgb3c2432" class="outline-5">
<h5 id="orgb3c2432"><span class="section-number-5">4.1.2.2</span> 常用命令</h5>
<div class="outline-text-5" id="text-4-1-2-2">
<div class="org-src-container">
<pre class="src src-sh">kubectl replace -f rs-def.yml
kubectl scale --replicas=6 -f rs-def.yml
kubectl scale --replicas=6 replicaset &lt;name&gt;
</pre>
</div>
</div>
</div>
</div>
</div>
</div>


<div id="outline-container-org11b6311" class="outline-2">
<h2 id="org11b6311"><span class="section-number-2">5</span> Utils</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org2bba3ed" class="outline-3">
<h3 id="org2bba3ed"><span class="section-number-3">5.1</span> Bash completion</h3>
<div class="outline-text-3" id="text-5-1">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #a6e22e;">source</span> &lt;(kubectl completion bash | sed s/kubectl/&lt;your_alias&gt;/g)
</pre>
</div>
</div>
</div>


<div id="outline-container-orgfa9dd1e" class="outline-3">
<h3 id="orgfa9dd1e"><span class="section-number-3">5.2</span> Show all resources</h3>
<div class="outline-text-3" id="text-5-2">
<div class="org-src-container">
<pre class="src src-sh">kubectl get
</pre>
</div>
</div>
</div>

<div id="outline-container-org059ee1a" class="outline-3">
<h3 id="org059ee1a"><span class="section-number-3">5.3</span> Discover possible API object fields</h3>
<div class="outline-text-3" id="text-5-3">
<div class="org-src-container">
<pre class="src src-sh">kubectl explain pods
</pre>
</div>

<p>
You can then drill deeper to find out more about each attribute.
</p>

<div class="org-src-container">
<pre class="src src-sh">kubectl explain pod.spec
</pre>
</div>
</div>
</div>

<div id="outline-container-org05184e6" class="outline-3">
<h3 id="org05184e6"><span class="section-number-3">5.4</span> Quickly switch to a different namespace</h3>
<div class="outline-text-3" id="text-5-4">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #a6e22e;">alias</span> <span style="color: #fd971f;">kcd</span>=<span style="color: #e6db74;">'kubectl config set-context $(</span><span style="color: #fa8072;">kubectl</span><span style="color: #e6db74;"> config current- context) --namespace '</span>
</pre>
</div>

<p>
You can then switch between namespaces using <code>kcd &lt;some-namespace&gt;</code>
</p>
</div>
</div>

<div id="outline-container-orgdc335f1" class="outline-3">
<h3 id="orgdc335f1"><span class="section-number-3">5.5</span> Forwarding a local network port to a port in the pod</h3>
<div class="outline-text-3" id="text-5-5">
<p>
Using port forwarding like this is an effective way to test an individual pod.
</p>

<div class="org-src-container">
<pre class="src src-sh">kubectl port-forward &lt;pod-name&gt; &lt;local-port&gt;:&lt;pod-port&gt;
</pre>
</div>
</div>
</div>


<div id="outline-container-org82ae919" class="outline-3">
<h3 id="org82ae919"><span class="section-number-3">5.6</span> Obtaining the application log of a crashed container</h3>
<div class="outline-text-3" id="text-5-6">
<p>
You can print the application’s log with kubectl logs. If your container is restarted, the kubectl logs command will show the log of the current container.
</p>

<p>
When you want to figure out why the previous container terminated, you’ll want to see those logs instead of the current container’s logs.
This can be done by using the <code>--previous</code> option:
</p>

<div class="org-src-container">
<pre class="src src-sh">kubectl logs &lt;pod&gt; --previous
</pre>
</div>
</div>
</div>

<div id="outline-container-orgd476888" class="outline-3">
<h3 id="orgd476888"><span class="section-number-3">5.7</span> Get IPs of all nodes</h3>
<div class="outline-text-3" id="text-5-7">
<div class="org-src-container">
<pre class="src src-sh">kubectl get nodes -o <span style="color: #fd971f;">jsonpath</span>=<span style="color: #e6db74;">'{.items[*].status.addresses[?(@.type=="ExternalIP")].address}'</span>
</pre>
</div>

<p>
To learn more about how to use JSONPath with kubectl, refer to the [To learn more about how to use JSONPath with kubectl, refer to the <a href="http://kubernetes.io/docs/user-guide/jsonpath">documentation</a>.
</p>
</div>
</div>
</div>
</div>
</body>
</html>