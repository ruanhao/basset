#+TITLE:     Python3
#+AUTHOR:    Hao Ruan
#+EMAIL:     haoru@cisco.com
#+LANGUAGE:  en
#+LINK_HOME: http://www.github.com/ruanhao
#+OPTIONS:   h:6 html-postamble:nil html-preamble:t tex:t f:t ^:nil
#+STARTUP:   showall
#+TOC:       headlines 4
#+HTML_DOCTYPE: <!DOCTYPE html>
#+HTML_HEAD: <link href="http://fonts.googleapis.com/css?family=Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />
#+HTML_HEAD: <link href="../org-html-themes/solarized/style.css" rel="stylesheet" type="text/css" />
#+HTML: <div class="outline-2" id="meta">
| Author   | {{{author}}} ({{{email}}})    |
| Date     | {{{time(%Y-%m-%d %H:%M:%S)}}} |
#+HTML: </div>


#+BEGIN_SRC ipython :session :exports none
  def log(title0, value):
      title1 = ' ' + title0 + ' '
      print("{}\n{}".format(title1.center(30, '='), value))
#+END_SRC


* 类

** 抽象类

*** 内置抽象基类

大多数内置抽象基类在 =collection.abc=, =numbers= 和 =io= 模块中定义，
=collection.abc= 中的抽象基类最常用。

[[https://docs.python.org/3/library/collections.abc.html#collections-abstract-base-classes][collection.abc 中各个抽象基类的总结]]


*** 自定义抽象基类

抽象基类中的抽象方法可以有实现代码。

即使实现了， *子类也必须覆盖抽象方法* ，但是在子类中可以使用 =super()= 函数调用抽象方法。


#+BEGIN_SRC ipython :session :exports both :results output
  from abc import ABC, abstractmethod

  class Pet(ABC):
      @classmethod
      def from_name(cls, name):
          for s_cls in cls.__subclasses__():  # 注意 __subclasses__ 的用法
              if name == s_cls.__name__.lower():
                  return s_cls()

      @abstractmethod
      def hello(self):
          pass

  class Dog(Pet):

      def hello(self):
          print("WonWonWon")

  Pet.from_name("dog").hello()
#+END_SRC

*** 虚拟子类

注册虚拟子类的方式是在抽象基类上调用 =register= 方法，
=register= 方法通常作为普通函数调用，也可以作为装饰器使用。

这么做之后，注册的类会变成抽象基类的虚拟子类，而且 =issubclass= 和 =isinstance= 都能识别，
*但是注册的类不会从抽象基类中继承任何方法或属性* 。

#+BEGIN_SRC ipython :session :exports both :results output
  @Pet.register
  class Cat:
      pass

  class Bird(list):
      pass

  Pet.register(Bird)

  log("issubclass(Cat, Pet)", issubclass(Cat, Pet))
  log("isinstance(Bird(), Pet)", isinstance(Bird(), Pet))
  log("Bird.__mro__", Bird.__mro__)
#+END_SRC

虚拟子类的 =__mro__= 属性中没有虚拟基类，也从侧面反映了虚拟子类没有从虚拟基类中继承任何方法。


** 继承

直接子类化内置类型 (如 =dict=, =list= 或 =str=) 容易出错，
因为内置类型的方法通常会忽略用户覆盖的方法。

*不要子类化内置类型* ，用户自己定义的类应该继承 =collection= 模块中的类，
如 UserDict, UserList 和 UserString ，这些类 *做了特殊设计* ，因此易于扩展。


* 并发编程

** 全局解释锁 (GIL)

CPython 解释器本身不是线程安全的，因此有全局解释器锁 (GIL) ，一次只允许使用一个线程执行 Python 字节码。因此，一个 Python 进程不能同时使用多个 CPU 。

***  I/O 密集型操作

标准库中所有执行阻塞型 I/O 操作的函数，在等待操作系统返回结果时都会释放 GIL 。
这意味着在 Python 语言这个层次上可以使用多线程，I/O 密集型的程序能从中受益。
( =time.sleep()= 函数也会释放 GIL)

*** CPU 密集型操作

使用 ProcessPoolExecutor 类把工作分配给多个进程处理可以实现真正的并行运算。因此，如果需要做 CPU 密集型处理，可以使用它绕开 GIL ，从而利用所有可用的 CPU 。(多个 Python 进程有各自独立的 GIL 锁，互不影响)


** concurrent.futures 模块

concurrent.futures 模块的主要特色是 ThreadPoolExecutor 和 ProcessPoolExecutor 类，
这两个类实现的接口能分别在不同的线程或进程中执行可调用的对象。

通常情况下 future 对象不应由用户创建，而是由并发框架 (concurrent.futures 或 asyncio) 来实例化。

*** Executor.map()

*Executor.map(func, *iterables, timeout=None, chunksize=1)*

chunksize 只对 ProcessPoolExecutor 有用，用于切分 iterables ，提高运行效率。

因为 future 结果的返回涉及到 IPC ，如果每个进程每次消耗 iterables 中的一个数据，整个过程涉及多个 IPC ，这样效率不高；但如果对 iterables 进行切分，N 个 数据同时交给一个进程进行处理，运算结果通过一个 IPC 一并返回，这样就可以提升效率。

返回值是一个迭代器， *迭代器的 __next__ 方法调用各个 future 对象的 result 方法，得到各个 future 的结果。*

#+BEGIN_SRC ipython :session :exports both :results output
  from concurrent.futures import ThreadPoolExecutor
  import time

  def sleep_and_double(value):
      time.sleep(value)
      return value * 2

  with ThreadPoolExecutor(max_workers=4) as executor:
      time0 =time.time()
      values = executor.map(sleep_and_double, [3, 2, 1])
      time_delta = time.time() - time0
      print("time consumed0: ", time_delta)
      print(values)
      time0 =time.time()
      print([v for v in values])
      time_delta = time.time() - time0
      print("time consumed1: ", time_delta)
#+END_SRC

*** Executor.sumit()

=Executor.sumit(fn, *args, **kwargs)=

#+BEGIN_SRC ipython :session :exports both :results output
  with ThreadPoolExecutor(max_workers=1) as executor:
      time0 = time.time()
      future = executor.submit(sleep_and_double, 3)
      time_delta = time.time() - time0
      print("time consumed0: ", time_delta)
      time0 = time.time()
      print(future.result())
      time_delta = time.time() - time0
      print("time consumed1: ", time_delta)
#+END_SRC


*** concurrent.futures.as_completed()

*concurrent.futures.as_completed(fs, timeout=None)*

#+BEGIN_SRC ipython :session :exports both :results output
  from concurrent import futures
  fs = []

  with ThreadPoolExecutor(max_workers=5) as executor:
      for i in [5, 4, 3, 2, 1]:
          f = executor.submit(sleep_and_double, i)
          fs.append(f)
      time0 = time.time()
      finishes = futures.as_completed(fs)
      time_delta = time.time() - time0
      print("time consumed0: ", time_delta)
      time0 = time.time()
      print([f.result() for f in finishes])
      time_delta = time.time() - time0
      print("time consumed1: ", time_delta)
#+END_SRC


* async 并发编程

*适合 asyncio API 的协程在定义体中必须使用 yield from ，而不能用 yield 。*

** asyncio 基本思想 (面向事件编程)

在 asyncio 中，基本的流程和 [[simulation][使用协程进行离散事件仿真]] 中提到的是一样的：

1. 在一个单线程中使用主循环依次激活队列里的协程
2. 各个协程向前执行几步，然后把控制权让给主循环
3. 主循环再激活队列里的下一个协程

编写基于 asyncio 的程序需注意下述细节：

- 编写的协程链始终通过把最外层委派生成器传给 asyncio 包中的某个函数驱动，例如 =loop.run_until_complete()= 。即我们的代码不通过调用 =next()= 函数或 =send()= 方法驱动协程。驱动由 asyncio 包实现的事件循环去做。

- 编写的协程链最终通过 =yield from= 把职责委托给 asyncio 包中的某个协程函数，如 =yeild from asyncio.sleep()= ，或者其他库中实现高层协议的协程，如 =response = yield from aiohttp.request('GET', url)= 。也就是说，最内层的子生成器是库中真正执行 I/O 操作的函数，而不是我们自己编写的函数。

概括起来就是：使用 asyncio 包时，我们编写的代码中包含委派生成器，
而生成器最终把职责 *委托* 给 asyncio 包或第三方库中的协程。
这种处理方式相当于架起了管道，让 asyncio 事件循环驱动执行低层异步 I/O 操作的库函数。


** @asyncio.coroutine

交给 asyncio 处理的协程要使用 =@asyncio.coroutine= 装饰，这虽不是强制要求，但是建议这么做。
因为这样能在一众普通函数中把协程凸显出来，也有助于调试：如果还没从协程中产出值，协程就被垃圾回收了，可以发出警告。
也可以使用 *async* 关键字。


** asyncio.Future

在 asyncio 包中，=BaseEventLoop.create_task()= 方法接收一个协程，排定它的运行时间，
然后返回一个 asyncio.Task 实例，也是 asyncio.Future 类的实例，因为前者是后者的子类，用于包装协程。

asyncio.Future 类的目的是与 =yield from= 一起使用，通常不需要使用以下方法：

- 无需调用 =asyncio.Future.add_done_callback()=

  因为可以直接把在 Future 运行结束后执行的操作放在 =yield from= 表达式后面。
- 无需调用 =asyncio.Future.result()=

  因为 =yield from= 从 Future 对象中产出的值就是结果，例如： =result = yield from my_future= 。


*** 从 Future ，Task ，和协程中产出值

在 asyncio 包中，可以这样写： =result = yield from foo()= ，其中 foo 可以是协程函数，或者是返回 asyncio.Future 或 Task 实例的普通函数， *这是 asyncio 包的 API 中很多地方可以互换协程和 Future 对象的原因之一。*

获取 Task 对象有两种主要方式：

- =asyncio.async(coro_or_future, *, loop=None)=

  这个函数排定了协程的运行时间并统一了协程和 Future ：如果第一个参数是 Future 或 Task 对象，则原封不动地返回；如果是协程，则会调用 =loop.create_task()= 方法创建 Task 对象。loop 关键词参数是可选的，用于传入事件循环，如果没有传入，则将调用 =asyncio.get_event_loop()= 获取。

- =BaseEventLoop.create_task(coro)=

  这个方法排定了协程的执行时间，返回 Task 对象。


*** 协程和 Future 测试脚本

#+BEGIN_SRC ipython :session :exports both :results output
  import asyncio
  import time

  def run_sync(coro_or_future):
      loop = asyncio.get_event_loop()
      return loop.run_until_complete(coro_or_future)

  async def test_coro():
      time0 = time.time()
      await asyncio.sleep(3)
      time_delta = time.time() - time0
      return time_delta

  result = run_sync(test_coro())
  log("result", result)
#+END_SRC


** 常用 API

*** BaseEventLoop.run_in_executor()

*BaseEventLoop.run_in_executor(executor, func, *args)*

asyncio 的事件循环在背后维护着一个 ThreadPoolExecutor 对象，
可以调用 run_in_executor 方法，把可调用对象发给它执行。

第一个参数是 Executor 实例，如果为 None ，则使用默认的 ThreadPoolExecutor 实例。

#+BEGIN_SRC ipython
  loop = asyncio.get_event_loop()
  loop.run_in_executor(None, )
#+END_SRC


*** asyncio.as_complete()

*asyncio.as_complete(fs, *, loop=None, timeout=None)*

#+BEGIN_SRC ipython :session :exports both :results output
  import asyncio
  import time

  async def foo(seconds):
      await asyncio.sleep(seconds)
      return seconds

  async def coro():
      fs = [foo(10), foo(5), foo(1)]
      for f in asyncio.as_completed(fs):
          time0 = time.time()
          result = await f
          print(result, "delta", time.time() - time0)

  asyncio.get_event_loop().run_until_complete(coro())
#+END_SRC


*** asyncio.Semaphore

*asyncio.Semaphore(value=1, *, loop=None)*

Semaphore 类用于限制并发请求数量。

Semaphore 对象维护一个内部计数器:

- 如果在对象上调用 =acquire()= 方法，计数器递减；
- 如果调用 =release()= 方法，计数器递增。

可以把 Semaphore 对象 _当作上下文管理器使用_ 。


#+BEGIN_SRC ipython :session :exports both :results output
  time0 = time.time()

  async def foo(semaphore):
      with (await semaphore):
          await asyncio.sleep(2)
          print("time delta:", time.time() - time0)

  async def coro():
      semaphore = asyncio.Semaphore(3)
      fs = [foo(semaphore) for _ in range(5)]
      for f in asyncio.as_completed(fs):
          await f

  asyncio.get_event_loop().run_until_complete(coro())
#+END_SRC


*** asyncio.wait()

*asyncio.wait(futures, *, loop=None, timeout=None, return_when=ALL_COMPLETED)*

参数是一个由 Future 或协程构成的可迭代对象，wait 会分别把各个协程包装进一个 Task 对象。
wait 是协程函数，因此它 *不会阻塞* ，默认行为是等传给它的所有协程运行完毕后结束。

#+BEGIN_SRC ipython :session :exports both :results output
  import random
  async def foo():
      sec = random.randint(1, 3)
      await asyncio.sleep(sec)
      return sec

  to_do = [foo() for _ in range(10)]
  wait_coro = asyncio.wait(to_do)
  result = asyncio.get_event_loop().run_until_complete(wait_coro)
  log("result", result)
#+END_SRC



* 上下文管理

** for/else, while/else, try/else

在所有情况下，如果因为异常或者 return，break 或 continue 语句导致控制权跳到了块之外，else 子句也会被跳过。

- for/else

  仅当 for 循环运行完毕时 (即 for 循环没有被 break 语句中止) 才运行 else 块。

- while/else

  仅当 while 循环因为条件为假值而退出时 (即 while 循环没有被 break 语句中止) 才运行 else 块。

- try/else

  仅当 try 块中没有异常抛出时才运行 else 块， *else 子句抛出的异常不会由前面的 except 子句处理。*

** with

with 语句的目的是简化 try/finally 模式。

上下文管理器协议包含 =__enter__= 和 =__exit__= 两个方法:

- with 语句开始运行时，会在上下文管理器对象上调用 =__enter__= 方法。
- with 语句运行结束后，会在上下文管理器对象上调用 =__exit__= 方法，以此扮演 finally 子句的角色。

=__exit__= 方法如果返回 True 之外的值 (包括 None) ，则 with 块中的任何异常都会向上冒泡。
如果返回 True ，即告诉解释器，异常已经处理了。


** contextlib 模块中的实用工具

*** closing

如果对象提供了 =close()= 方法，但没有实现 =__enter__/__exit__= 协议，则可以用这个函数构建上下文管理器。

#+BEGIN_SRC ipython :session :exports both :results output
  from contextlib import closing

  class Door:

      def open(self):
          print("door opened")

      def close(self):
          print("door closed")

  with closing(Door()) as door:
      door.open()
#+END_SRC


*** suppress

构建忽略指定异常的上下文管理器。

#+BEGIN_SRC ipython :session :exports both :results output
  from contextlib import suppress
  import os

  with suppress(FileNotFoundError):
      os.remove('somefile.tmp')
#+END_SRC

*** redirect

#+BEGIN_SRC ipython :session :exports both :results output
  import io
  from contextlib import redirect_stdout

  f = io.StringIO()
  with redirect_stdout(f):
      help(pow)

  log("f.getvalue()", f.getvalue())
#+END_SRC

#+BEGIN_SRC ipython :session :exports both :results output
  with open('/tmp/help.txt', 'w') as f:
      with redirect_stdout(f):
          help(pow)
#+END_SRC


*** @contextmanager

这个装饰器把简单的生成器函数变成上下文管理器，这样就不用创建类去实现管理器协议了。

在使用 @contextmanager 装饰的生成器中，yield 语句的作用是把函数的定义体分成两部分：

- yield 语句前面的所有代码在 with 块开始时 (即解释器调用 =__enter__= 方法时) 执行
- yield 语句后面的代码在 with 块结束时 (即调用 =__exit__= 方法时) 执行


#+BEGIN_SRC ipython :session :exports both :results output
  from contextlib import contextmanager

  class Query(object):

      def __init__(self, name):
          self.name = name

      def query(self):
          print('Query info about %s...' % self.name)

  @contextmanager
  def create_query(name):
      print('Begin')
      with suppress(Exception):
          yield Query(name)  # 需要使用 as
      print('End')

  with create_query('Bob') as q:
      q.query()
#+END_SRC


#+BEGIN_SRC ipython :session :exports both :results output
  @contextmanager
  def tag(name):
      print("<%s>" % name, end='')
      with suppress(Exception):
          yield  # 无需使用 as
      print("</%s>" % name)

  with tag("h1"):
      print("hello", end='')
#+END_SRC

本质上，contextlib.contextmanager 装饰器会把函数包装成实现了 =__enter__= 和 =__exit__= 方法的类 (类的名称是 _GeneraorContextManager) 。这个类的 =__enter__= 方法有如下作用：

- 调用生成器函数，保存生成器对象 (这里把它成为 gen)
- 调用 =next(gen)= ，执行到 yield 关键字所在位置
- 返回上一步 =next(gen)= 产出的值，以便把产出的值绑定到 with/as 语句中的目标变量上

with 块终止时， =__exit__= 方法会做以下几件事：

- 检查有没有异常，如果有，调用 =gen.throw(ex)= ，在生成器函数定义体中包含 yield 关键字的那一行抛出异常
- 否则，调用 =next(gen)= ，继续执行生成器函数定义体中 yield 语句之后的代码


*注意:*

如果在 with 块中抛出了异常，Python 解释器会将其捕获，然后会在生成器函数中 yield 表达式处再次抛出。因此使用 @contextmanager 装饰器时，要把 yield 语句放在 try/finally 语句中 (或者放在 with 语句中) ，这是无法避免的，因为我们永远不知道使用上下文管理器的用户会在 with 块中做什么。

另外，@contextmanager 装饰器提供的 =__exit__= 方法假定发给生成器的所有异常都得到处理了，因此应该压制异常。如果不想让 @contextmanager 压制异常，必须在被装饰的函数中显示重新抛出异常。


* 协程

协程是指一个过程，这个过程与调用方协作，产出由调用方提供的值。

协程中的关键字 yield 可以视作控制流程的方式。

** 状态

可以使用 =inspect.getgeneratorstate()= 获取协程四个状态中的一个：

1. GEN_CREATED：等待开始执行
2. GEN_RUNNING：正在执行
3. GEN_SUSPENDED：在 yield 表达式处暂停
4. GEN_CLOSED：执行结束


** send()

仅当协程 cr 处于暂停状态才能调用 send 方法。

如果协程还没激活 (即状态是 GEN_CREATED) ，可以调用 =cr.send(None)= 激活协程，这和使用 =next(cr)= 效果一样。


** 执行过程举例


#+NAME: coroutine
#+CAPTION: 协程执行过程
[[file:img/py3_coroutine.png]]

1. 调用 =next(my_coro2)= ，打印第一个消息，然后执行 yield a ，产出数字 14
2. 调用 =my_coro2.send(28)= ，把 28 赋值给 b ，打印第二个消息，然后执行 =yield a + b= ，产出 42
3. 调用 =my_coro2.send(99)= ，把 99 赋值给 c ，打印第三个消息，协程终止

注意，各个阶段都在 yield 表达式中结束，而且下一个阶段都从那一行代码开始，然后再把 yield 表达式的值赋给变量。



** 预激 (prime) 协程的装饰器

如果不预激，则协程没什么用，即调用 =send()= 之前，一定要先调用 =next()= 。

如果无需调用 =send()= ，即 yield 只是为了产出值的情况下，则不需要预激。

有时可以自定义一个预激装饰器以简化协程的用法：

#+BEGIN_SRC ipython
  from functools import wraps

  def coroutine(func):

      @wraps(func)
      def primer(*args, **kwargs):
          gen = func(*args, **kwargs)
          next(gen)
          return gen

      return primer
#+END_SRC

*注意* ：

使用 yield from 调用协程时，会自动预激，因此与上面的做法不兼容。
标准库里的 asyncio.coroutine 装饰器不会预激协程，因此可以兼容 yield from 语法。


** 终止协程和异常处理

协程中未处理的异常会向上冒泡，传给调用协程的对象，未处理的异常会导致协程终止。


*** generator.throw()

=generator.throw(exc_type[, exc_value[, traceback]])=

该方法会导致生成器在暂停的 yield 表达式处抛出指定的异常。
如果生成器内部处理了该异常，代码会向前执行到下一个 yield 表达式处，而产出的值会成为该方法的返回值。
如果生成器内部没有处理这个异常，异常会向上冒泡，传到调用方的上下文中。


*** generator.close()

该方法使得生成器在暂停的 yield 表达式处抛出 GeneratorExit 异常。
如果生成器内部没有处理这个异常，调用方不会报错。如果收到 GeneratorExit 异常，生成器不能产出值，否则解释器会抛出 RuntimeError 异常。

如果不管协程如何结束都需要做清理工作，需要把协程定义体中相关的代码放入 try/finally 块中。


** 有返回值的协程

在 Python3.3 之前，如果生成器返回值，解释器会报错。

return 的值会偷偷传给调用方，赋值给 StopIteration 异常的一个属性。这样的做法有点奇怪，但是能保留住生成器对象的常规行为，即耗尽时抛出 StopIteration 异常。

#+BEGIN_SRC ipython :session :exports both :results output
  from collections import namedtuple
  Result = namedtuple('Result', 'count average')

  def averager():
      total = 0.0
      count = 0
      average = None
      while True:
          term = yield
          if term is None:
              break
          total += term
          count += 1
          average = total / count
      return Result(count, average)

  c_avg = averager()
  next(c_avg)
  c_avg.send(10)
  c_avg.send(20)
  try:
      c_avg.send(None)
  except StopIteration as exc:
      result = exc.value

  log("result", result)
#+END_SRC


** yield from

在生成器 gen 中使用 =yield from subgen()= 时，subgen 会获得控制权，把产出的值传给 gen 的调用方，即调用方可以直接控制 subgen 。与此同时，gen 会阻塞，等待 subgen 终止。

从定义上来说，yield from 的主要功能是打开双向通道，把最外层的调用方与最内层的子生成器连接起来，这样二者可以直接发送和产出值，还可以直接传入异常。


*** 结构示意图

#+NAME: yield
#+CAPTION: yield from 工作原理
[[file:img/py3_yield.png]]

委派生成器在 yield from 表达式处暂停时，调用方可以直接把数据发给子生成器，子生成器再把产出的值发给调用方。
子生成器返回之后，解释器抛出 StopIteration 异常，并把返回值附加到异常对象上，届时委派生成器恢复。

委派生成器相当于 *管道* ，可以吧任意数量的委派生成器连接在一起，
这个管道最终要以一个只使用 yield 表达式的简单生成器结束 (也能以任何可迭代对象结束) 。
任何 yield from 链都必须由客户驱动，即在最外层委派生成器上调用 =next()=, =send()= 方法，
也可以隐式调用，如使用 for 循环。


*** yield from 意义

- 子生成器产出的值都直接传给委派生成器的调用方，即客户端。
- 使用 =send()= 发给委派生成器的值都直接传给子生成器。如果发送的值是 None ，那么会调用子生成器的 =__next__()= 方法。如果不是 None ，那么会调用子生成器的 send() 方法。如果调用的方法抛出 StopIteration 异常，那么委派生成器恢复运行。任何其他异常都会向上冒泡，传给委派生成器。
- 生成器退出时，子生成器中的 =return expr= 表达式会触发 =StopIteration(expr)= 异常抛出。
- yield from 表达式的值是子生成器终止时传给 StopIteration 异常的第一个参数。
- 传入委派生成器的异常，除了 GeneratorExit 之外都传给子生成器的 =throw()= 方法。如果调用 =throw()= 方法抛出 StopIteration 异常，委派生成器恢复运行。StopIteration 之外的异常会向上冒泡，传给委派生成器。
- 如果把 GeneratorExit 异常传入委派生成器，或者在委派生成器上调用 =close()= 方法，则会在子生成器上调用 =close()= 方法 (如果它有的话) 。如果子生成器调用 =close()= 方法导致异常抛出，则异常会向上冒泡，传给委派生成器，如果没有异常抛出，则委派生成器会抛出 GeneratorExit 异常。


**** RESULT = yield from EXPR 执行逻辑

#+BEGIN_SRC ipython
  # _i: The subgenerator
  # _y: A value yielded from the subgenerator
  # _r: The eventual result
  # _s: A value sent by the caller to the delegating generator, which is forwarded to the subgenerator
  # _e: An exception

  _i = iter(EXPR)
  try:
      _y = next(_i)
  except StopIteration as _e:
      _r = _e.value
  else:
      while 1:
          try:
              _s = yield _y
          except GeneratorExit as _e:
              try:
                  _m = _i.close
              except AttributeError:
                  pass
              else:
                  _m()
              raise _e
          except BaseException as _e:
              _x = sys.exc_info()
              try:
                  _m = _i.throw
              except AttributeError:
                  raise _e
              else:
                  try:
                      _y = _m(*_x)
                  except StopIteration as _e:
                      _r = _e.value
                      break
          else:
              try:
                  if _s is None:
                      _y = next(_i)
                  else:
                      _y = _i.send(_s)
              except StopIteration as _e:
                  _r = _e.value
                  break

  RESULT = _r
#+END_SRC



** <<simulation>>使用协程进行离散事件仿真

这个例子是说明如何在一个主循环中处理事件，以及如何通过发送数据驱动协程。这是 asyncio 包底层的基本思想。

#+BEGIN_SRC ipython :session :exports both :results output
  from collections import namedtuple
  import queue
  import random

  Event = namedtuple('Event', 'time proc action')

  def taxi_process(proc, trips, start_time=0):
      time = yield Event(start_time, proc, 'leave garage')
      for i in range (trips):
          time = yield Event(time, proc, 'pick up passenger')
          time = yield Event(time, proc, 'drop off passenger')
      yield Event(time, proc, 'going home')

  class Simulator:

      def __init__(self, procs_map):
          self.events = queue.PriorityQueue()
          self.procs = dict(procs_map)

      def run(self, end_time):
          for _, proc in sorted(self.procs.items()):
              first_event = next(proc)
              self.events.put(first_event)

          sim_time = 0
          while sim_time < end_time:
              if self.events.empty():
                  print('=== end of events ===')
                  break

              current_event = self.events.get()
              sim_time, proc_id, action = current_event
              print('taxi:', proc_id, proc_id * '  ', action, ' [', sim_time, ']')
              active_proc = self.procs[proc_id]
              next_time = sim_time + random.randint(1, 10)
              try:
                  next_event = active_proc.send(next_time)
              except StopIteration:
                  del self.procs[proc_id]
              else:
                  self.events.put(next_event)
          else:
              print('=== end of simulation time: {} events pending ==='
                    .format(self.events.qsize()))

  num_taxis = 3
  DEPARTURE_INTERVAL = 5
  taxis = {i: taxi_process(i, (i+1)*2, i*DEPARTURE_INTERVAL) for i in range(num_taxis)}
  Simulator(taxis).run(100)
#+END_SRC


* 数据结构

** 元组

*** 基本用法

**** 占位

=a, _ = (3, 4)=

**** 星号(*)的使用

#+BEGIN_SRC ipython :session :exports both :results output
  a, b, *rest1 = range(5)
  log("rest1", rest1)

  a, b, *rest2 = range(3)
  log("rest2", rest2)

  a, b, *rest3 = range(2)
  log("rest3", rest3)
#+END_SRC

*星号前缀只能用在一个变量名前，但是这个变量可以出现在赋值表达式的任意位置：*

#+BEGIN_SRC ipython :session :exports both :results output
  a, *body, c, d = range(5)
  log("body", body)

  *head, b, c, d = range(5)
  log("head", head)
#+END_SRC

**** 嵌套拆包

#+BEGIN_SRC ipython :session :exports both :results output
  name, cc, pop, (latitude, longitude) = ('Tokyo', 'JP', 36.933, (35.689722, 139.691667))
  log("[name, cc, pop, latitude, longitude]", [name, cc, pop, latitude, longitude])
#+END_SRC


** 具名元组

#+BEGIN_SRC ipython :session :exports both :results output
  from collections import namedtuple
  Point = namedtuple('Point', ['x', 'y'])
  p = Point(1, 2)
  print("x: {}, y: {}".format(p.x, p.y))
#+END_SRC

除了从普通元组继承来的属性之外，具名元祖还有一些自己专用的属性：

#+BEGIN_SRC ipython :session :exports both :results output
  # _fields 属性包含这个类所有字段名称的元组
  log("Point._fields", Point._fields)

  data = (3, 4)
  pt = Point._make(data)  # 作用等效于 Point(*data)
  log("pt._asdict()", pt._asdict())

#+END_SRC


** 列表

切片操作里不包含区间范围的最后一个元素是 Python 的风格，这个习惯带来的好处如下：

- 当只有最后一个位置信息时，可以快速看出有几个元素：=range(3)= 和 =my_list[:3]= 都返回 3 个元素
- 当起止位置信息都可见时，可以快速计算出区间长度，即 =stop - start=
- 可以利用任意一个下标把序列分割成不重叠的两部分，只需写成： =my_list[:3]= 和 =my_list[3:]=

*** 切片选择

#+BEGIN_SRC ipython :session :exports both :results output
  s = 'bicycle'
  log("s[::3]", s[::3])

  # 反序
  log("s[::-1]", s[::-1])

  # 复制序列
  log("s[:]", s[:])

#+END_SRC


*** 切片赋值

#+BEGIN_SRC ipython :session :exports both :results output
  l = list(range(10))
  log("l", l)

  l[2:5] = [20, 30]
  log("l[2:5] = [20, 30]", l)

  del l[5:7]
  log("del l[5:7]", l)

  l[3::2] = [11, 22]
  log("l[3::2] = [11, 22]", l)

  print('test exception'.center(30, '='))
  try:
      l[2:5] = 100
  except Exception as e:
      print(e)

  l[2:5] = [100]
  log("l[2:5] = [100]", l)

#+END_SRC



** bisect

*** 搜索

#+BEGIN_SRC ipython :session :exports both :results output
  import bisect
  def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):
      i = bisect.bisect(breakpoints, score)
      return grades[i]

  result = [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]
  log("result", result)
#+END_SRC


*** 插入新元素

#+BEGIN_SRC ipython :session :exports both :results output
  import bisect
  import random
  random.seed(1729)
  SIZE = 20
  my_list = []
  for i in range(SIZE):
      new_value = random.randrange(SIZE*2)
      bisect.insort(my_list, new_value)

  log("my_list", my_list)
#+END_SRC


** 数组

如果需要一个只包含数字的列表，使用 array.array 比 list 更高效。

创建数组需要一个类型码，用来表示底层的 C 语言应存放怎样的数据类型。

#+BEGIN_SRC ipython :session :exports both :results output
  from array import array
  from random import random
  floats = array('d', (random() for i in range(1000)))  # 'd' 表示双精度浮点
  log("floats[-1]", floats[-1])
#+END_SRC


** 内存视图

memoryview 是一个内置类，能让用户在不复制内容的情况下，在数据结构之间共享内存，
*这个功能在处理大型数据集合时非常重要。*

#+BEGIN_SRC ipython :session :exports both :results output
  # 通过改变数组中的一个字节来更新数组里某个元素的值
  import array
  numbers = array.array('h', [-2, -1, 0, 1, 2])  # 'h' 表示 16 位二进制整数
  memv = memoryview(numbers)

  # memoryview.cast 会把同一块内存里的内容打包成一个全新的 memoryview
  memv_oct = memv.cast('B')   # 'B' 表示无符号字符
  memv_oct[5] = 4

  log("numbers", numbers)
#+END_SRC


** 双向队列

collection.deque 是一个线程安全，可以快速从两端添加或删除元素的数据类型。

使用 list 存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，
因为 list 是线性存储，数据量大的时候，插入和删除效率很低。
deque 是为了高效实现插入和删除操作的双向列表，适合用于队列和栈。

如果想要一种数据结构来存放 *最近用到的几个元素* ，deque 是一个很好的选择。


#+BEGIN_SRC ipython :session :exports both :results output
  from collections import deque
  dq = deque(range(10), maxlen=10)
  log("dq", dq)

  dq.rotate(3)
  log("dq.rotate(3)", dq)

  dq.rotate(-4)
  log("dq.rotate(-4)", dq)

  dq.appendleft(-1)
  log("dq.appendleft(-1)", dq)

  dq.extend([11, 22, 33])
  log("dq.extend([11, 22, 33])", dq)

#+END_SRC


** 生成器

*生成器保存的是算法* ，每次调用 =next(g)= ，就计算出 g 的下一个元素的值，
直到计算到最后一个元素，没有更多的元素时，抛出 StopIteration 异常。

*** 生成器函数

当 Python 函数定义体中有 yield 关键字，该函数就是生成器函数。
调用生成器函数时，会返回一个生成器对象。也就是说生成器函数是生成器工厂，
*而生成器表达式是生成器函数的语法糖。*


*** 标准库中的生成器函数

**** 用于过滤的生成器函数

- itertools.compress(it, selector_it)

  并行处理两个可迭代对象：如果 selector_it 中的元素是真值，产出 it 中对应的元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    import itertools
    def vowel(c):
        return c.lower() in 'aeiou'

    result = list(itertools.compress('Aardvark', (1, 0, 1, 1, 0, 1)))
    print(result)
#+END_SRC


- itertools.dropwhile(predicate, it)

  处理 it ，跳过 predicate 计算结果为真值的元素，产出剩下的元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.dropwhile(vowel, 'Aardvark')))
#+END_SRC


- builtin.filter(predicate, it)

  如果 =predicate(item)= 返回真值，产出对应的元素，如果 predicate 是 None ，则只产出真值元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(filter(vowel, 'Aardvark')))
#+END_SRC


- itertools.filterfalse(predicate, it)

  如果 =predicate(item)= 返回假值，产出对应的元素。


- itertools.islice(it, [start], stop, step=1)

  产出 it 的切片，类似于 =s[:stop]= 或 =s[start:stop:step]= 。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.islice('Aardvark', 4)))
    print(list(itertools.islice('Aardvark', 4, 7)))
    print(list(itertools.islice('Aardvark', 1, 7, 2)))
#+END_SRC

- itertools.takewhile(predicate, it)

  如果 =predicate(item)= 返回真值，产出对应的元素，然后停止。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.takewhile(vowel, 'Aardvark')))
#+END_SRC


**** 用于映射的生成器函数

- itertools.accumulate(it, [func])

  产出累计值，默认为求和；如果提供了 func ，则把前面两个元素传个 func ，
  然后把计算结果和下一个元素传给它，以此类推，最后产出结果。

  #+BEGIN_SRC ipython :session :exports both :results output
    from operator import mul
    sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1]

    print(list(itertools.accumulate(sample)))
    print(list(itertools.accumulate(sample, min)))
    print(list(itertools.accumulate(sample, mul)))

  #+END_SRC


- builtin.enumerate(it, start=0)

  产出有两个元素组成的元组，结构是 (index, item) ，其中 index 从 start 开始计数，item 则从 iterable 中获取。

- builtin.map(func, it1, [it2, ..., itN])

  如果传入 N 个 可迭代对象，则 func 必须能接受 N 个参数。

- itertools.starmap(func, it)

  把 it 中各个元素传给 func ，产出结果。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.starmap(mul, enumerate('albatroz', 1))))
    print(list(itertools.starmap(lambda a, b: b/a,
                                 enumerate(itertools.accumulate(sample), 1))))
  #+END_SRC


**** 用于合并可迭代对象的生成器函数

- itertools.chain(it1, ..., itN)

  无缝连接多个可迭代对象。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.chain('ABC', range(3))))
  #+END_SRC


- itertools.chain.from_iterable(it)

  产出 it 生成的各个可迭代对象中的元素，无缝连接在一起。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.chain.from_iterable(enumerate('ABC'))))
  #+END_SRC


- itertaools.product(it1, ..., itN, repeat=1)

  计算笛卡尔积，合并成由 N 个元素组成的元组。
  repeat 关键字参数告诉 product 函数重复 N 次处理输入的各个可迭代对象。

  #+BEGIN_SRC ipython :session :exports both :results output
  print(list(itertools.product('ABC', range(2))))
  # list(itertools.product('ABC', 'ABC'))
  print(list(itertools.product('ABC', repeat=2)))
  #+END_SRC

- builtin.zip(it1, .., itN)

  产出由 N 个元素组成的元组，只要有一个可迭代对象到头了，即停止。

  #+BEGIN_SRC ipython :session :exports both :results output
  print(list(zip('ABC', range(5), [10, 20, 30, 40, 50, 60])))
  #+END_SRC

- itertools.zip_longest(it1, ..., itN, fillvalue=None)

  产出由 N 个元素组成的元组，等到最长的可迭代对象到头了，即停止。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.zip_longest('ABC',
                                     range(5),
                                     [10, 20, 30, 40, 50, 60],
                                     fillvalue='?')))
  #+END_SRC


**** 用于扩展输出元素的生成器函数

- itertools.combinations(it, out_len)

  把 it 产出的 out_len 个元素组合在一起，然后产出。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.combinations('ABC', 2)))
  #+END_SRC

- itertools.combinations_with_replacement(it, out_len)

  把 it 产出的 out_len 个元素组合在一起，然后产出，包含相同元素的组合。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.combinations_with_replacement('ABC', 2)))
  #+END_SRC

- itertools.permutation(it, out_len=None)

  把 out_len 个 it 产出元素排列在一起，然后产出这些排列；out_len 的默认值等于 =len(list(it))= 。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.permutations('ABC', 2)))
  #+END_SRC

- itertools.count(start=0, step=1)

  从 start 开支不断产出数字，按 step 步幅增加。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.islice(itertools.count(1, .3), 3)))
  #+END_SRC

- itertools.cycle(it)

  从 it 中产出元素，存储各个元素的 *副本* ，然后按顺序重复不断地产出各个元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.islice(itertools.cycle('ABC'), 7)))
  #+END_SRC


- itertools.repeat(item, [times])

  不断产出指定元素，除非指定次数。常见用途，为 map 函数提供固定参数：

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(map(mul, range(11), itertools.repeat(5))))
  #+END_SRC


- builtin.iter(callable, sentinel)

  第一个参数是一个没有参数的可调用对象，用于不断调用，产出各个值；第二个值是哨符，当可调用对象返回这个值时，迭代结束 (不产出哨符) 。

  iter 的[[https://docs.python.org/3/library/functions.html#iter][文档]]中有个实用的例子，这段代码逐行读取文件，直到遇到空行或到达文件末尾为止：

  #+BEGIN_SRC ipython
    with open('mydata.txt') as fp:
        for line in iter(fp.readline, ''):
            process_line(line)
  #+END_SRC


**** 用于重新排列元素的生成器函数

- itertools.groupby(it, key=None)

  产出由两个元素组成的元组，形式为 (key, group) ，其中 key 是分组标准，group 是生成器，用于产出分组里的元素。

  注意， =itertool.groupby= 假定输入的可迭代对象已使用指定的 key 分组了各个元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(itertools.groupby('LLLAAGGG')))
    print(list(itertools.groupby('LLAALAAGGG')))
  #+END_SRC

  #+BEGIN_SRC ipython :session :exports both :results output
    animals = ['duck', 'eagle', 'rat', 'giraffe', 'bear', 'bat', 'dolphin', 'shark', 'lion']
    animals.sort(key=len)
    for length, group in itertools.groupby(animals, len):
        print(length, '->', list(group))
  #+END_SRC


- builtin.reversed(seq)

  seq 必须是序列，或是实现了 =__reversed__= 特殊方法的对象。

- itertools.tee(it, n=2)

  产出一个由 n 个生成器组成的元组，每个生成器用于单独产出输入的可迭代对象中的元素。

  #+BEGIN_SRC ipython :session :exports both :results output
    print(list(zip(*itertools.tee('ABC'))))
  #+END_SRC


*** yield from 语法

这个语句的作用是把不同的生成器结合在一起使用。


#+BEGIN_SRC ipython :session :exports both :results output
  def chain(*iterables):
      for it in iterables:
          for i in it:
              yield i

  print(list(chain('ABC', range(3))))
#+END_SRC


*等效于：*

#+BEGIN_SRC ipython :session :exports both :results output
  def chain(*iterables):
      for i in iterables:
          yield from i

  print(list(chain('ABC', range(3))))
#+END_SRC

*** 把生成器当成协程

[[https://www.python.org/dev/peps/pep-0342/][PEP 342]] 为生成器对象添加了 =send()= 方法，该方法使得生成器前进到下一个 yield 语句。

=send()= 方法还允许使用生成器的客户把数据发给自己，传给 =send()= 方法的参数，
会成为生成器函数定义体中对应 yield 表达式的值。
也就是说，=send()= 方法允许在客户代码和生成器之间 *双向交换数据。*

*生成器用于生成供迭代的数据，而协程是数据的消费者，协程与迭代无关。*


** 字典

*** 广义映射类型

#+BEGIN_SRC ipython :session :exports both :results output
  from collections import abc
  d = {}
  print(isinstance(d, abc.Mapping))
#+END_SRC

*** 字典构造

#+BEGIN_SRC ipython :session :exports both :results output
  a = dict(one=1, two=2, three=3)
  b = {'one': 1, 'two': 2, 'three': 3}
  c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))
  d = dict([('two', 2), ('one', 1), ('three', 3)])
  e = dict({'three': 3, 'one': 1, 'two': 2})
  print(a == b == c == d == e)
#+END_SRC


*** 字典推导

#+BEGIN_SRC ipython :session :exports both :results output
  CODES = [
      (86, 'China'),
      (91, 'India'),
      (1, 'USA')
  ]
  print({country: code for code, country in CODES})

#+END_SRC

*** 弹性键查询

**** defaultdict

在实例化一个 defaultdict 的时候，需要给构造方法提供一个可调用对象，
这个可调用对象会在 =__getitem__= 找不到键的时候被调用，以便 =__getitem__= 返回默认值。

#+BEGIN_SRC ipython :session :exports both :results output
  import collections
  d = collections.defaultdict(list)
  d['a'].append('b')
  d['c'].append('d')
  log("d", d)
#+END_SRC


**** =__missing__=

映射类型在处理找不到的键的时候，都会涉及 =__missing__= 方法。
虽然基类 dict 没有定义这个方法，但是如果一个类继承了 dict ，然后提供了 =__missing__= 方法，
那么当 =__getitem__= 遇到找不到键的时候，Python 会自动调用它，而不是抛出 KeyError 异常。

*__missing__ 方法只会被 __getitem__ 调用（即使用表达式 d[k] ）*



*** OrderedDict

这个类型在添加键的时候会保持顺序，因此键的迭代次序总是一致的。

OrderedDict 的 popitem 方法默认删除并返回字典里最后一个元素，
但是如果调用 =popitem(last=False)= ，则删除并返回第一个被添加进去的元素。


*** ChainMap

该类型可以容纳多个不同的映射对象，在进行键查找操作时，会逐个查找这些映射对象，直到键被找到为止。

这个功能在给有嵌套作用域的语言做解释器的时候很有用，可以用一个映射对象来代表一个作用域上下文。

#+BEGIN_SRC ipython
  import builtins
  from collections import ChainMap
  pylookup = ChainMap(locals(), globals(), vars(builtins))

#+END_SRC


*** Counter

这个映射类型会给键准备一个整数计数器，每次更新一个键的时候会增加这个计数器。

Counter 实现了 + 和 - 运算符来合并记录。 =most_common([n])= 方法会返回最常见的 n 个键和它们的计数。

#+BEGIN_SRC ipython :session :exports both :results output
  from collections import Counter
  ct = Counter('abracadabra')
  print(ct)
  ct.update('aaaaazzz')
  print('after update'.center(30, '='))
  print(ct)
  print(ct.most_common(2))
#+END_SRC


*** UserDict

这个类其实是把标准 dict 用纯 Python 又实现了一遍，主要的用途是让用户继承写子类的。

更倾向于从 UserDict 而不是从 dict 继承的主要原因是后者有时会在某些方法的实现上走一些捷径，
导致不得不在子类中重写这些方法（比如 dict 的子类实现的 =__getitem__= 方法不会被 get() 方法所调用），
但是 UserDict 就不会有这个问题。

#+BEGIN_SRC ipython :session :exports both :results output
  class MyDict(dict):
      def __setitem__(self, key, value):
          super().__setitem__(key, value*2)

  d = MyDict(one=1)
  print(d)

  d['two'] = 2
  print(d)
#+END_SRC


继承自 dict 的 =__init__= 方法忽略了子类的 =__setitem__= 方法。

#+BEGIN_SRC ipython :session :exports both :results output
  d.update(three=3)
  print(d)
#+END_SRC

继承自 dict 的 update 方法也忽略了子类的 =__setitem__= 方法。

另外一个值得注意的地方是，UserDict 并不是 dict 的子类。
UserDict 有一个 data 属性，是 dict 的实例，这个属性实际上是 UserDict 最终存储数据的地方。


*** 不可变映射类型

types.MappingProxyType 会返回一个只读的映射视图。
虽然是只读视图，但是它是动态的，如果对原映射做出改动，
通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。

#+BEGIN_SRC ipython :session :exports both :results output
  from types import MappingProxyType
  d = {1: 'A'}
  d_proxy = MappingProxyType(d)
  print(d_proxy)

  log("d_proxy[1]", d_proxy[1])

  try:
      d_proxy[2] = 'x'
  except Exception as e:
      print(e)

  d[2] = 'B'
  print(d_proxy)
#+END_SRC

** 集合

*** 创建

#+BEGIN_SRC ipython :session :exports both :results output
  s = {1, 2, 3, 1, 2, 3}
  print(s)
  s = set()  # 空集须写成 set()
  print(s)
  s = frozenset(range(10))
  print(s)
  s = { c for c in 'helloworld'}
  print(s)
#+END_SRC

*** 合集，交集，差集

- 合集： =a | b=
- 交集： =a & b=
- 差集： =a - b=


*** Hash 算法

#+BEGIN_SRC plantuml :file img/p3_hash.png
  :计算键的散列值;
  :使用散列值最低的几位数字来定位散列表用的一个表元(bucket);
  while (表元为空) is (否)
      if (键相等) then (是)
          : 返回表元里的值;
          stop
      else (否)
          : 在散列值中另外再取几位来定位散列表中的另一个表元;
          note right: 散列冲突
      endif
  endwhile (是)
      :KeyError;
#+END_SRC
#+NAME: hash
#+CAPTION: 哈希算法

如果实现了一个类的 =__eq__= 方法，并且希望它是可散列的，
则一定需要有一个恰当的 =__hash__= 方法，保证在 a == b 为真的情况下 hash(a)==hash(b) 也必定为真。

如果一个含有自定义 =__eq__= 方法的类处于可变的状态，就不要在这个类中实现 =__hash__= 方法，
因为它的实例是不可散列的。


* 函数

** 提取函数签名

#+BEGIN_SRC ipython :session :exports both :results output
  from inspect import signature

  def foo(a, b=1, **c):
      pass

  sig = signature(foo)
  log("sig", sig)

  result = [(name, param.default) for name, param in sig.parameters.items()]
  log("result", result)
#+END_SRC


inspect.Signature 对象有个 bind 方法，可以把任意个参数绑定到签名中的形参上，
所用的规则与实参到形参的匹配方式一样。框架可以使用这个方法在真正调用函数前验证函数：

#+BEGIN_SRC ipython :session :exports both :results output
  args = {'a': 'aaa', 'b': 'bbb', 'x': 'xxx', 'y': 'yyy'}
  bound_args = sig.bind(**args)
  result = [(name, value) for name, value in bound_args.arguments.items()]
  print(result)
#+END_SRC


#+BEGIN_SRC ipython :session :exports both :results output
  del args['a']
  try:
      sig.bind(**args)
  except Exception as e:
      print(e)
#+END_SRC


** 支持函数式编程的模块

得益于 operator 和 functools 等模块的支持，可以编写函数式风格的 Python 代码。

*** operator 模块

operator 模块为多个算术运算符提供了对应的函数，
从而避免编写类似 =lambda a, b: a * b= 这种平凡的匿名函数：

#+BEGIN_SRC ipython :session :exports both :results output
  from functools import reduce
  from operator import mul

  print(reduce(mul, range(1, 6)))
#+END_SRC


**** itemgetter

operator 模块中还有一类函数，能替代从序列中取出元素或读取对象属性的 lambda 表达式：

#+BEGIN_SRC ipython :session :exports both :results output
  from operator import itemgetter

  data = [
      ('c', 2),
      ('b', 3),
      ('a', 1)
  ]

  print(sorted(data, key=itemgetter(0)))
#+END_SRC

如果把多个参数传给 itemgetter ，它构建的函数会返回提取的值构成的元组：

#+BEGIN_SRC ipython :session :exports both :results output
  print([itemgetter(1, 0)(t) for t in data])
#+END_SRC


**** attrgetter

attrgetter 与 itemgetter 作用类似，它创建的函数根据名称提取对象的属性。
如果把多个属性名传给 attrgetter ，它也会返回提取的值构成的元组。

此外，如果参数名中包含 *.* ，attrgetter 会深入嵌套对象，获取指定的属性。



**** methodcall

methodcall 会自行创建函数，该函数会在对象上调用参数指定的方法：

#+BEGIN_SRC ipython :session :exports both :results output
  from operator import methodcaller
  s = "hello world"
  upcase = methodcaller('upper')
  print(upcase(s))

  hiphenate = methodcaller('replace', ' ', '-')
  print(hiphenate(s))
#+END_SRC


** 闭包

闭包是一种函数，它会保留定义函数时存在的 *自由变量(free variable)* 的绑定，
这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定。

#+BEGIN_SRC ipython :session :exports both :results output
  def make_averager():
      series = []

      def averager(new_value):
          series.append(new_value)
          total = sum(series)
          return total/len(series)

      return averager

  avg = make_averager()
  avg(10)
  avg(11)
  avg(12)

  log("avg.__code__.co_varnames", avg.__code__.co_varnames)

  log("avg.__code__.co_freevars", avg.__code__.co_freevars)
#+END_SRC

=__closure__= 中的各个元素对应于 =__code__.co_freevars= 中的一个名称：

#+BEGIN_SRC ipython :session :exports both :results output
  log("avg.__closure__", avg.__closure__)

  log("avg.__closure__[0].cell_contents",
      avg.__closure__[0].cell_contents)
#+END_SRC

*** nonlocal

nonlocal 的作用是把变量标记为自由变量。

#+BEGIN_SRC ipython :session :exports both :results output
  def make_averager():
      count = 0
      total = 0

      def averager(new_value):
          nonlocal count, total
          count += 1
          total += new_value
          return total / count

      return averager

  avg = make_averager()
  avg(1)
  avg(2)
  print(avg(3))
#+END_SRC


*** 闭包的陷阱

#+BEGIN_SRC ipython :session :exports both :results output
  def count():
      fs = []
      for i in range(1, 4):
          def f():
               return i*i
          fs.append(f)
      return fs

  f1, f2, f3 = count()

  print(f1(), f2(), f3())

#+END_SRC

需注意： *闭包中不要引用任何可能会变化的变量。* 如果一定要引用会变化的变量，可以再创建一个函数：

#+BEGIN_SRC ipython :session :exports both :results output
  def count():
      def f(j):
          def g():
              return j*j
          return g
      fs = []
      for i in range(1, 4):
          fs.append(f(i))
      return fs

  f1, f2, f3 = count()
  print(f1(), f2(), f3())
#+END_SRC


** 装饰器

*** functool.wraps

#+BEGIN_SRC ipython :session :exports both :results output
  import functools
  import time

  def clock(func):
      @functools.wraps(func)
      def wrapper(*args, **kw):
          t0 = time.perf_counter()
          result = func(*args, **kw)
          elapsed = time.perf_counter() - t0
          name = func.__name__
          arg_lst = []
          if args:
              arg_lst.append(', '.join(repr(arg) for arg in args))
          if kw:
              pairs = ['{}={}'.format(k, w) for k, w in sorted(kw.items())]
              arg_lst.append(', '.join(pairs))
          arg_str = ', '.join(arg_lst)
          print("[{:0.8f}] {}({}) -> {}".format(elapsed, name, arg_str, result))
          return result
      return wrapper

  @clock
  def snooze():
      time.sleep(1)

  snooze()
#+END_SRC


*** functools.lru_cache

这是一项优化技术，它把耗时的函数的结果缓存起来，避免传入相同的参数时重复计算。
lru_cache 可以使用两个可选的参数来配置：

*functools.lru_cache(maxsize=128, typed=False)*

maxsize 指定存储多少个调用的结果。缓存满了之后，旧的结果会被删除，腾出空间。
为了得到最佳性能，maxsize 应设为 2 的幂。
typed 参数如果设为 True ，把不同参数类型得到的结果分开保存，
即把通常认为相等的浮点数和整数参数(如 1 和 1.0)区分开。

因为 lru_cache 使用字典存储结果，而且键根据调用时传入的定位参数和关键字参数创建，
因此被 lru_cache 装饰的函数，它的所有参数必须是可散列的。

#+BEGIN_SRC ipython :session :exports both :results output
  @clock
  def fib(n):
      if n < 2: return n
      return fib(n-2) + fib(n-1)

  print("result: ", fib(6))
#+END_SRC

#+BEGIN_SRC ipython :session :exports both :results output
  import functools

  @functools.lru_cache()
  @clock
  def fib(n):
      if n < 2:
          return n
      return fib(n-2) + fib(n-1)

  print("result:", fib(6))
#+END_SRC

*** functools.singledispatch

使用 @singledispatch 装饰的普通函数会变成分派函数，
或称为泛函数 (generic function) ： *根据第一个参数的类型，选择对应的函数。*

分派函数：

#+BEGIN_SRC ipython
  def handle_value(value):
      if isinstance(value, int):
          handle_value_int(value)
      elif isinstance(value, str):
          handle_value_str(value)
      else:
          handle_value_defalut(value)
#+END_SRC


@singledispatch 的优点是支持模块化扩展：各个模块可以为它支持的各个类型注册一个专门的函数。

#+BEGIN_SRC ipython :session :exports both :results output
  from functools import singledispatch
  from collections import abc
  import numbers

  @singledispatch
  def fun(arg, verbose=False):
      if verbose:
          print("Let me just say,", end=" ")
      print(arg)

  @fun.register(numbers.Integral)
  def _(arg, verbose=False):  # 函数名称无关紧要
      if verbose:
          print("Strength in numbers, eh?", end=" ")
      print(arg)

  @fun.register(abc.MutableSequence)
  @fun.register(tuple)  # 可以叠放多个 register 装饰器，以支持不同的类型
  def handle_seq(arg, verbose=False):
      if verbose:
          print("Enumerate this:")
      for i, elem in enumerate(arg):
          print(i, elem)

  fun("3", True)
  fun(3, True)
  fun((3,), True)

  log("fun.dispatch(tuple)", fun.dispatch(tuple))
  log("fun.registry.keys()", fun.registry.keys())
#+END_SRC


注册的专门函数应该处理抽象基类 (如 numbers.Integral 和 abc.MutableSequence) ，
不要处理具体实现 (如 int 和 list) ，这样，代码支持的兼容类型更广泛。

** 参数

在 Python 中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，
这 5 种参数都可以组合使用。

组合参数定义的 *顺序* 必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。

*** 命名关键字参数

命名关键字参数可以用于限制关键字参数的名字。
命名关键字参数必须传入参数名，如果没有传入参数名，调用将报错。

#+BEGIN_SRC ipython
  # 只接收 city 和 job 作为关键字参数
  def person(name, age, *, city, job):             # 命名关键字参数需要一个特殊分隔符 *
      print(name, age, city, job)                  # * 后面的参数被视为命名关键字参数

  def person2(name, age, *, city='Beijing', job):  # 可以有默认值
      print(name, age, city, job)

  # 如果函数定义中已经有了一个可变参数
  # 后面跟着的命名关键字参数就不再需要一个特殊分隔符 * 了
  def person(name, age, *args, city, job):
      print(name, age, args, city, job)
#+END_SRC

*** 默认参数

*定义默认参数时，默认参数必须指向不可变对象。*

#+BEGIN_SRC ipython :session :exports both :results output
  def add_end(L=[]):
      L.append('END')
      return L

  print(add_end())
  print(add_end())
  print(add_end())

#+END_SRC

原因：

函数在定义的时候，默认参数 L 的值就被计算出来了，即 [] ，且保存在函数对象中。
每次调用该函数，如果改变了 L 的内容，则下次调用时，默认参数的内容就变了。

可以用 None 这个不可变对象来实现：

#+BEGIN_SRC ipython
  def add_end(L=None):
      if L is None:
          L = []
          L.append('END')
          return L
#+END_SRC



* 模块

** 包目录结构

#+BEGIN_EXAMPLE
  cisco
  ├── __init__.py
  ├── csg
  │   ├── __init__.py
  │   ├── modA.py
  │   └── modB.py
  ├── modA.py
  └── modB.py
#+END_EXAMPLE

每一个包目录下面都会有一个 =__init__.py= 的文件，这个文件是必须存在的，
否则，Python 就把这个目录当成普通目录，而不是一个包。

=__init__.py= 可以是空文件，也可以有 Python 代码，
因为 =__init__.py= 本身就是一个模块，而它的模块名就是目录名。



* 对象

** == 与 is

== 比较两个对象的值 (对象中保存的数据)，而 is 比较对象的标识。

a==b 等同于 =a.__eq__(b)= 。
继承自 object 的 =__eq__= 方法比较两个对象的 ID ，结果与 is 一样。
但多数内置类型使用更有意义的方式覆盖了 =__eq__= 方法，会考虑对象属性的值。

** 弱引用

- 弱引用不会增加对象的引用数量，不会妨碍所指对象被当作垃圾回收
- 弱引用是可调用对象，如果对象存在，调用弱引用可以获取对象，否则返回 None
- 弱引用在缓存应用中很有用，因为一般不希望由于被缓存引用着而始终保存缓存对象

#+BEGIN_SRC ipython :session :exports both :results output
  import weakref
  a = {0, 1}
  wref = weakref.ref(a)
  print(wref())
#+END_SRC

weakref.ref 类是低层接口，
*应该多使用 WeakKeyDictionary, WeakValueDictionary, WeakSet 和 finalize ，*
不要自己动手创建并处理 weakref.ref 实例。


*** weakref.finalize

#+BEGIN_SRC ipython :session :exports both :results output
  import weakref
  s = {1, 2, 3}
  ender = weakref.finalize(s, lambda: print("Gone with the wind ..."))
  print(ender.alive)
#+END_SRC

#+BEGIN_SRC ipython :session :exports both :results output
  # del 不会删除对象，但是执行 del 后可能会导致对象不可获取，从而被删除
  del s

#+END_SRC


*** weakref.WeakValueDictionary

WeakValueDictionary 类实现的是一种可变映射， *里面的值是对象的弱引用* 。
被引用的对象在程序中的其他地方被当作垃圾回收后，对应的键会自动从 WeakValueDictionary 中删除。因此，WeakValueDictionary 经常用于缓存。

#+BEGIN_SRC ipython :session :exports both :results output
  import weakref

  class Cheese:

      def __init__(self, kind):
          self.kind = kind

  stock = weakref.WeakValueDictionary()
  catalog = [Cheese('Read Leicester'), Cheese('Tilsit'), Cheese('Brie'), Cheese('Parmesan')]
  for cheese in catalog:
      stock[cheese.kind] = cheese

  print(sorted(stock.keys()))

  del catalog
  del cheese
  print(sorted(stock.keys()))
#+END_SRC


*** weakref.WeakKeyDictionary

与 WeakValueDictionary 对应的是 WeakKeyDictionary ，后者的键是弱引用。

***  weakref.WeakSet

保存元素弱引用的集合类。元素没有强引用时，集合会把它删除。

如果一个类需要知道所有实例，一种好的方案是创建一个 WeakSet 类型的类属性，用以保存实例的引用。

*** 弱引用的局限

不是每个 Python 对象都可以作为弱引用的目标 (或称所指对象) 。
list 和 dict 实例不能作为所指对象，但是它们的子类可以。
int 和 tuple 实例不能作为弱引用的目标，甚至它们的子类也不行。这些局限是内部优化导致的结果。


** =__slots__=


默认情况下，Python 在各个实例中名为 =__dict__= 的字典里存储实例属性。
为了使用底层的散列表提升访问速度，字典会消耗大量内存。
如果要处理数百万个属性不多的实例，通过 =__slots__= 类属性，能节省大量内存。
*其本质是让解释器在元组中存储实例属性，而不是使用字典。*

继承自超类的 =__slots__= 属性 *没有效果* ，Python 只会使用 *各个类中自己定义* 的 =__slots__= 属性。

不要使用 =__slots__= 禁止类的用户新增实例属性，使用 =__slots__= 是 *为了优化，不是为了约束。*

*** 节省的内存也可能被再次吃掉

如果把 =__dict__= 这个名称添加到 =__slots__= 中，
实例会在元祖中保存各个实例的属性，同时还支持动态创建属性，但这样就失去了节省内存的功效。


*** 让对象支持弱引用

为了让对象支持弱引用，必须要有 =__weakref__= 这个属性。

用户定义的类中默认就有这个属性。如果类中定义了 =__slots__= 属性，
而且想把实例作为弱引用的目标，那么必须把 =__weakref__= 添加到 =__slots__= 中。


* 元编程

** =__new__=

我们通常把 =__init__= 称为构造方法，其实，用于构建实例的是特殊方法 =__new__= ：
这是个类方法，由于使用了特殊方式处理，因此不必使用 @classmethod 装饰器，该方法必须返回一个实例。
返回的实例会作为第一个参数 (即 self) 传给 =__init__= 方法。

因为调用 =__init__= 方法时要传入实例，而且禁止返回任何值，所以 =__init__= 其实称为初始化方法更为合适。
*真正的构造方法是* =__new__= 。
几乎不需要自己编写 =__new__= 方法，因为从 object 类继承的实现已经足够了。

*注意* ： =__new__= 方法也可以返回其他类的实例，此时，解释器不会调用 =__init__= 方法。

Python 构建对象的过程可以用下述伪代码概括：

#+BEGIN_SRC ipython
  def object_maker(the_class, some_arg):
      new_object = the_class.__new__(some_arg)
      if isinstance(new_object, the_class):
          the_class.__init__(new_object, some_arg)
      return new_object

  # 下述两个语句作用等效
  # x = Foo('bar')
  # x = object_maker(Foo, 'bar')
#+END_SRC

在 =__new__= 方法中调用 =super().__new__(cls)= 会调用 =object.__new__(cls)= ，
而 object 类构建的实例其实是 cls 实例，即实例的 =__class__= 属性存储的是 cls 类的引用。
(真正的构建操作由解释器调用 C 语言实现的 =object.__new__= 方法执行)


** 描述符

*** 属性查找

**** 从类中查找属性

使用 C.name 引用类对象 C 的一个属性时，查询操作如下：

1. 当 name 是 =C.__dict__= 中的一个键时， C.name 将从 =C.__dict__['name']= 中提取值 v。如果 v 是一个描述器，则 C.name 的值就是 =type(v).__get__(v, None, C)= ，否则，C.name 的值为 v
2. 否则，C.name 将委托查找 C 的基类
3. 否则引发 AttributeError


**** 从实例中查找属性

=obj.attr= 这样的表达式 *不会从 obj 开始寻找 attr* ，而是从 =obj.__class__= 开始，
*仅当类中没有名为 attr 的描述符时，才会在 obj 实例中寻找。*

使用 x.name 引用类 C 的实例 x 的一个属性时，查询操作如下：

1. 当 name 作为一个覆盖描述器 v 的名称在类 C （或 C 的某个祖先类）中被找到，x.name 的值就是 =type(v).__get__(v, x, C)=
2. 否则，当 name 是 =x.__dict__= 中的一个键时，返回 =x.__dict__['name']=
3. 否则，x.name 将委托查找 x 的类，即查找 C.name
4. 如果 C 定义或继承了特殊方法 =__getattr__= ，则调用 =C.__getattr__(x, 'name')= ，而不是引发 AttributeError，然后根据 =__getattr__= 返回一个合适的值或者引发 AttributeError


*** 覆盖型描述符

也叫作数据描述符或强制描述符。

实现 =__set__= 方法的描述符属于覆盖型描述符，虽然描述符是类属性，
但是实现了 =__set__= 方法的话，会覆盖对实例属性的赋值操作。

内置的 property 类创建的其实是覆盖型描述符， =__set__= 方法和 =__get__= 方法都实现了，
=__set__= 方法默认抛出 AttributeError 异常。

**** 没有 __get__ 方法的覆盖型描述符

通过实例读取描述符会返回描述符对象本身。如果直接通过实例的 =__dict__= 属性创建同名实例属性，
以后再设置那个属性时，仍会由 =__set__= 方法接管，
但是读取那个属性时，会直接从实例中返回新赋的值，而不会返回描述符对象。
也就是说，实例属性会遮盖描述符，不过只有读操作如此。


*** 非覆盖型描述符

也叫作非数据描述符或遮盖型描述符。

没有实现 =__set__= 方法的描述符是非覆盖型描述符。
如果设置了同名的实例属性，描述符会被覆盖，致使描述符无法处理那个实例的那个属性。
*方法是* 以非覆盖型描述符实现的 (只有 =__get__= 方法) 。

非覆盖型描述符可以用来实现缓存，执行某些耗费资源的计算，然后为实例设置同名属性，缓存结果。
同名属性会遮盖描述符，因此后续访问会直接从实例的 =__dict__= 属性中获取值，不会触发描述符的 =__get__= 方法。



** 元类

*** 使用 type 动态创建类

#+BEGIN_SRC ipython :session :exports both :results output
  def fn(self, name='world'):
      print('Hello, %s.' % name)

  Hello = type('Hello', (object,), dict(hello=fn))

  h = Hello()
  print((type(Hello), type(h)))
#+END_SRC


*** 使用 metaclass 控制类的创建

所有类都是 type 的实例，元类是 type 的子类，可以作为制造类的工厂。
具体来说，元类可以通过实现 =__init__= 方法定制实例。
元类的 =__init__= 方法可以做到类装饰器能做的任何事情。
(如果想进一步定制类，可以在元类中实现 =__new__= 方法。不过，通常情况下实现 =__init__= 方法就够了)

#+BEGIN_SRC ipython :session :exports both :results output
  class MetaFoo(type):

      def __new__(metacls, name, bases, attrs):
          print("metacls: {}, name: {}, bases: {}, attrs: {}".format(metacls, name, bases, attrs))
          return type.__new__(metacls, name, bases, attrs)

      def __init__(cls, name, bases, attrs): # name, bases, attrs: 与构建类时传给 type 的参数一样
          print("cls: {}, name: {}, bases: {}, attrs: {}".format(cls, name, bases, attrs))

  class Foo(str, metaclass=MetaFoo):
      pass

  print(dir(Foo))
#+END_SRC


*** =__prepare__=

type 构造方法及元类的 =__new__= 和 =__init__= 方法都会收到要计算的类的定义体，
形式是名称到属性的映射，默认情况下，那个映射所使用的数据结构是字典。

Python3 引入了特殊方法 =__prepare__= ，这个特殊方法只在元类中有用，且必须声明为类方法。
解释器调用元类的 =__new__= 方法前会先调用该方法。
=__prepare__= 方法的第一个参数时元类，随后两个参数分别是要构建的类的名称和基类组成的元组，
返回值必须是映射类型。 =__prepare__= 返回的映射对象会传给 =__new__= 方法的最后一个参数，
然后再传给 =__init__= 方法。

=__prepare__= 的用法一般都比较简单，比如想要控制类的属性定义的顺序：

#+BEGIN_SRC ipython
  import collections

  class EntityMeta(type):

      @classmethod
      def __prepare__(cls, name, bases):
          return collections.OrderedDict()
#+END_SRC



* Unicode

** 字符编码工作方式

在计算机内存中，统一使用 Unicode 编码，当需要保存到硬盘或者需要传输的时候，就转换为 UTF-8 编码。

*Python 的字符串在内存中以 Unicode 表示* ，一个字符对应若干个字节。
如果要在网络上传输，或者保存到磁盘上， *就需要把字符串变为以字节为单位的 bytes* 。


#+BEGIN_EXAMPLE
  +---------------------------------------+
  |            Memory (Unicode)           |
  +-----------+----------------^----------+
              |                |
              |                |
  +-----------v----------------+----------+
  |            File (UTF-8)               |
  +---------------------------------------+
#+END_EXAMPLE


** Code Point 转换

#+BEGIN_SRC ipython :session :exports both :results output
  print(ord('A'))
  print(ord('中'))
  print(chr(66))
  print(chr(25991))
#+END_SRC


** 编解码

#+BEGIN_SRC ipython :session :exports both :results output
  print('ABC'.encode('ascii'))
  print('中文'.encode('utf-8'))
  print(b'ABC'.decode('ascii'))
  print(b'\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8'))
#+END_SRC


* 参考资料