#+TITLE:     Process and Thread
#+AUTHOR:    Hao Ruan
#+EMAIL:     ruanhao1116@gmail.com
#+LANGUAGE:  en
#+LINK_HOME: http://www.github.com/ruanhao
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../css/style.css" />
#+OPTIONS:   H:2 num:nil \n:nil @:t ::t |:t ^:{} _:{} *:t TeX:t LaTeX:t
#+STARTUP:   showall


* 一，基本知识

** 1.1，Python 对线程的限制

#+BEGIN_QUOTE
Python 的线程虽然是真正的线程，但解释器执行代码时，有一个 GIL 锁：Global Interpreter Lock 。
任何线程执行前，必须先获得 GIL 锁，然后，每执行 100 条字节码，解释器就自动释放 GIL 锁，让别的线程有机会执行。
这个 GIL 全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在 Python 中只能交替执行，
即使 100 个线程跑在 100 核 CPU 上，也只能用到 1 个核。

Python 虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。
多个 Python 进程有各自独立的 GIL 锁，互不影响。
#+END_QUOTE

** 1.2，协程

Python 语言中，单进程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。

Python 对协程的支持是通过 generator 实现的。

* 二，常见用法

- 启动子进程

  #+BEGIN_SRC python
    from multiprocessing import Process
    import os

    # 子进程要执行的代码
    def run_proc(name):
        print('Run child process %s (%s)...' % (name, os.getpid()))

    if __name__=='__main__':
        print('Parent process %s.' % os.getpid())
        p = Process(target=run_proc, args=('test',))
        print('Child process will start.')
        p.start()
        p.join()                    # 等待子进程结束后再继续往下运行
        print('Child process end.')
  #+END_SRC

- 创建进程池

  #+BEGIN_SRC python
    from multiprocessing import Pool
    import os, time, random

    def long_time_task(name):
        print('Run task %s (%s)...' % (name, os.getpid()))
        start = time.time()
        time.sleep(random.random() * 3)
        end = time.time()
        print('Task %s runs %0.2f seconds.' % (name, (end - start)))

    if __name__=='__main__':
        print('Parent process %s.' % os.getpid())
        p = Pool(4)
        for i in range(5):
            p.apply_async(long_time_task, args=(i,))
        print('Waiting for all subprocesses done...')
        p.close()
        p.join()  # Pool 对象调用 join() 方法会等待所有子进程执行完毕
                  # 调用 join() 之前必须先调用 close()
                  # 调用 close() 之后就不能继续添加新的 Process 了
        print('All subprocesses done.')
  #+END_SRC

- 控制子进程的输入输出

  #+BEGIN_SRC python
    import subprocess

    print('$ nslookup www.python.org')
    r = subprocess.call(['nslookup', 'www.python.org'])
    print('Exit code:', r)
  #+END_SRC

  如果子进程还需要输入，则可以通过 communicate() 方法提供：

  #+BEGIN_SRC python
    import subprocess

    print('$ nslookup')
    p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
    print(output.decode('utf-8'))
    print('Exit code:', p.returncode)

    # 相当于在命令行执行命令nslookup，然后手动输入：
    # set q=mx
    # python.org
    # exit
  #+END_SRC

- 进程间通行

  父进程中创建两个子进程，一个往 Queue 里写数据，一个从 Queue 里读数据：

  #+BEGIN_SRC python
    from multiprocessing import Process, Queue
    import os, time, random

    # 写数据进程执行的代码:
    def write(q):
        print('Process to write: %s' % os.getpid())
        for value in ['A', 'B', 'C']:
            print('Put %s to queue...' % value)
            q.put(value)
            time.sleep(random.random())

    # 读数据进程执行的代码:
    def read(q):
        print('Process to read: %s' % os.getpid())
        while True:
            value = q.get(True)
            print('Get %s from queue.' % value)

    if __name__=='__main__':
        # 父进程创建 Queue ，并传给各个子进程：
        q = Queue()
        pw = Process(target=write, args=(q,))
        pr = Process(target=read, args=(q,))
        # 启动子进程 pw ，写入:
        pw.start()
        # 启动子进程 pr ，读取:
        pr.start()
        # 等待 pw 结束:
        pw.join()
        # pr 进程里是死循环，无法等待其结束，只能强行终止:
        pr.terminate()
  #+END_SRC

- 启动线程

  #+BEGIN_SRC python
    import time, threading

    # 新线程执行的代码:
    def worker():
        print('thread %s is running...' % threading.current_thread().name)
        time.sleep(1)
        print('thread %s ended.' % threading.current_thread().name)

    t = threading.Thread(target=worker, name='WorkerThread')
    t.start()
    t.join()
  #+END_SRC

- 给线程加锁

  #+BEGIN_SRC python
    lock = threading.Lock()

    def run_thread(n):
        lock.acquire()
        try:
            do_something()
        finally:
            lock.release()
  #+END_SRC

- ThreadLocal

  一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。

  #+BEGIN_SRC python
    import threading

    # 创建全局 ThreadLocal 对象:
    local_school = threading.local()

    def process_student():
        # 获取当前线程关联的student:
        std = local_school.student
        print('Hello, %s (in %s)' % (std, threading.current_thread().name))

    def process_thread(name):
        # 绑定 ThreadLocal 的 student ：
        local_school.student = name
        process_student()

    t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
    t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
    t1.start()
    t2.start()

  #+END_SRC

  ThreadLocal 最常用的地方就是为每个线程绑定一个数据库连接，HTTP 请求，用户身份信息等，\\
  这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。

- 协程编写

  Python 的 yield 不但可以返回一个值，它还可以接收调用者发出的参数。

  用协程编写生产消费者模型：

  #+BEGIN_SRC python
    def consumer():
        r = ''
        while True:
            n = yield r
            if not n:
                return
            print('[CONSUMER] Consuming %s...' % n)
            r = '200 OK'

    def produce(c):
        c.send(None)
        n = 0
        while n < 5:
            n = n + 1
            print('[PRODUCER] Producing %s...' % n)
            r = c.send(n)
            print('[PRODUCER] Consumer return: %s' % r)
        c.close()

    c = consumer()
    produce(c)
  #+END_SRC

  生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产。

- asyncio 编程模型

  asyncio 编程模型就是一个消息循环。从 asyncio 模块中获取一个 EventLoop 的引用，然后把需要执行的协程放到 EventLoop 中执行，从而实现了异步 IO。

  #+BEGIN_SRC python
    import asyncio

    @asyncio.coroutine
    def hello():
        print("Hello world!")
        sleep_coroutine = asyncio.sleep(1)
        r = yield from sleep_coroutine  # 异步调用 asyncio.sleep(1):
        print("Hello again!")

    # 获取EventLoop:
    loop = asyncio.get_event_loop()
    # 执行coroutine
    loop.run_until_complete(hello())
    loop.close()

    # @asyncio.coroutine 把一个 generator 标记为 coroutine 类型，并把这个 coroutine 放到到 EventLoop 中执行。

    # hello() 会首先打印出 Hello world! ，然后，yield from 语法可以方便地调用另一个 generator 。
    # 由于 asyncio.sleep() 也是一个 coroutine ，所以线程不会等待 asyncio.sleep() ，而是直接中断并执行下一个消息循环。
    # 当 asyncio.sleep() 返回时，线程就可以从 yield from 拿到返回值（此处是None），然后接着执行下一行语句。

    # 把 asyncio.sleep(1) 看成是一个耗时 1 秒的 IO 操作，在此期间，主线程并未等待，
    # 而是去执行 EventLoop 中其他可以执行的 coroutine 了，因此可以实现并发执行。
  #+END_SRC

  1) asyncio 提供了完善的异步 IO 支持
  2) 异步操作需要在 coroutine 中通过 yield from 完成
  3) 多个 coroutine 可以封装成一组 Task 然后并发执行

  为了简化并更好地标识异步 IO ，从 Python 3.5 开始引入了新的语法 async 和 await ，可以让 coroutine 的代码更简洁易读。\\
  要使用新的语法，只需要做两步简单的替换：

  1. 把 @asyncio.coroutine 替换为 async
  2. 把 yield from 替换为 await

  #+BEGIN_SRC python
    async def hello():
        print("Hello world!")
        r = await asyncio.sleep(1)
        print("Hello again!")
  #+END_SRC
